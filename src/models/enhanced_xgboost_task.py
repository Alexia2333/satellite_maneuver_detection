# scripts/enhanced_xgboost_task.py
"""
ä½¿ç”¨Enhanced XGBoost Detectorçš„æ— ç›‘ç£æ£€æµ‹ä»»åŠ¡

ä»»åŠ¡ï¼š
1. è¯»å–æ•°æ®ï¼ˆä½¿ç”¨ç°æœ‰loaderï¼‰
2. ç”¨Enhanced XGBoostè¿›è¡Œæ— ç›‘ç£æ£€æµ‹
3. ç”¨æœºåŠ¨æ—¥å¿—æ£€æŸ¥å‡†ç¡®æ€§
4. æ¢æˆç²’å­æ»¤æ³¢æ–¹æ³•å†è¯•ä¸€æ¬¡

è¿è¡Œï¼špython scripts/enhanced_xgboost_task.py
"""

import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from sklearn.preprocessing import StandardScaler
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "src")))
from models.hybrid.xgboost_detector import create_labels_for_split


# æ·»åŠ è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)
sys.path.insert(0, os.path.join(project_root, 'src'))

print("ğŸš€ Enhanced XGBoostæ— ç›‘ç£æ£€æµ‹éªŒè¯")
print("=" * 50)

# =====================================================================
# ä»»åŠ¡1ï¼šè¯»å–æ•°æ®
# =====================================================================
def load_data():
    """ä»»åŠ¡1ï¼šä½¿ç”¨ç°æœ‰loaderè¯»å–æ•°æ®"""
    print("\nğŸ“‚ ä»»åŠ¡1ï¼šè¯»å–æ•°æ®")
    print("-" * 20)
    
    try:
        from data.loader import SatelliteDataLoader
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        loader = SatelliteDataLoader(data_dir="data")
        
        # åŠ è½½é£äº‘4Aæ•°æ®
        tle_data, maneuver_times = loader.load_satellite_data("Fengyun-4A")
        
        print(f"âœ… TLEæ•°æ®: {len(tle_data)} æ¡è®°å½•")
        print(f"âœ… æœºåŠ¨æ•°æ®: {len(maneuver_times)} ä¸ªäº‹ä»¶")
        
        if len(tle_data) > 0:
            print(f"   æ—¶é—´èŒƒå›´: {tle_data['epoch'].min()} åˆ° {tle_data['epoch'].max()}")
            print(f"   åˆ—å: {list(tle_data.columns)}")
        
        return tle_data, maneuver_times
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None, None

# =====================================================================
# ç‰¹å¾å·¥ç¨‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
# =====================================================================
def create_enhanced_features(tle_data, target_col='mean_motion'):
    """åˆ›å»ºå¢å¼ºç‰¹å¾ (å­¦ä¹ ç›®æ ‡å·²ä¿®æ­£)"""
    print("\nğŸ› ï¸ åˆ›å»ºå¢å¼ºç‰¹å¾")
    print("-" * 15)
    
    data = tle_data.set_index('epoch').copy()
    base_cols = ['mean_motion', 'eccentricity', 'inclination']
    available_cols = [col for col in base_cols if col in data.columns]
    
    if not available_cols:
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ°åŸºç¡€ç‰¹å¾åˆ—: {base_cols}")
        return None
    
    print(f"   åŸºç¡€ç‰¹å¾: {available_cols}")
    
    enhanced_data = data[available_cols].copy()
    
    # åˆ›å»ºæ»åã€æ»šåŠ¨ã€å·®åˆ†ç­‰ç‰¹å¾... (è¿™éƒ¨åˆ†é€»è¾‘ä¸å˜)
    lags = [1, 2, 3, 7]
    for col in available_cols:
        for lag in lags:
            enhanced_data[f'{col}_lag_{lag}'] = data[col].shift(lag)
    
    windows = [3, 7, 14]
    for col in available_cols:
        for window in windows:
            enhanced_data[f'{col}_rolling_mean_{window}'] = data[col].rolling(window).mean()
            enhanced_data[f'{col}_rolling_std_{window}'] = data[col].rolling(window).std()
            
    for col in available_cols:
        enhanced_data[f'{col}_diff_1'] = data[col].diff(1)
        enhanced_data[f'{col}_diff_7'] = data[col].diff(7)
    
    # --- ã€æ ¸å¿ƒä¿®æ­£ã€‘å­¦ä¹ ç›®æ ‡æ”¹ä¸ºé¢„æµ‹ç›®æ ‡åˆ—çš„â€œå˜åŒ–é‡â€ ---
    enhanced_data['target'] = enhanced_data[target_col].diff().shift(-1)
    
    enhanced_data = enhanced_data.dropna()
    
    print(f"âœ… å¢å¼ºç‰¹å¾åˆ›å»ºå®Œæˆ (å­¦ä¹ ç›®æ ‡: {target_col}çš„å˜åŒ–é‡)")
    print(f"   æœ‰æ•ˆè®°å½•: {len(enhanced_data)}")
    
    return enhanced_data

# =====================================================================
# ä»»åŠ¡2ï¼šEnhanced XGBoostæ— ç›‘ç£æ£€æµ‹
# =====================================================================
def enhanced_xgboost_detection(enhanced_data, maneuver_times):
    """ä»»åŠ¡2ï¼šEnhanced XGBoostæ— ç›‘ç£æ£€æµ‹ (é‡‡ç”¨æ ‡å‡†æµç¨‹é‡æ„)"""
    print("\nğŸ¤– ä»»åŠ¡2ï¼šEnhanced XGBoostæ£€æµ‹")
    print("-" * 30)
    
    try:
        from models.hybrid.enhanced_xgboost_detector import ImprovedXGBoostDetector
        from models.hybrid.xgboost_detector import create_labels_for_split

        # 1. ã€æ ‡å‡†åˆ’åˆ†ã€‘æŒ‰æ—¶é—´åˆ’åˆ†å‡ºè®­ç»ƒå‘¨æœŸå’Œæµ‹è¯•å‘¨æœŸ
        split_ratio = 0.7
        split_index = int(len(enhanced_data) * split_ratio)
        train_period_data = enhanced_data.iloc[:split_index]
        test_data = enhanced_data.iloc[split_index:]
        
        print(f"   è®­ç»ƒå‘¨æœŸæ•°æ®: {len(train_period_data)} æ¡")
        print(f"   æµ‹è¯•å‘¨æœŸæ•°æ®: {len(test_data)} æ¡")

        # 2. åœ¨è®­ç»ƒå‘¨æœŸå†…ï¼Œè¯†åˆ«å‡ºâ€œçº¯å‡€â€çš„æ­£å¸¸æ•°æ®ç”¨äºè®­ç»ƒ
        #    è¿™æ˜¯æ ‡å‡†çš„åšæ³•ï¼Œç”¨å·²çŸ¥ä¿¡æ¯æ„å»ºä¸€ä¸ªé«˜è´¨é‡çš„â€œæ­£å¸¸â€æ¨¡å‹
        train_period_labels = create_labels_for_split(
            train_period_data.index,
            maneuver_times,
            window=timedelta(days=1)
        )
        normal_mask = (train_period_labels == 0)
        normal_train_data = train_period_data[normal_mask]
        print(f"   ä»è®­ç»ƒå‘¨æœŸä¸­æå–å‡ºçº¯å‡€çš„æ­£å¸¸æ•°æ®: {len(normal_train_data)} æ¡")

        # 3. åˆå§‹åŒ–æ£€æµ‹å™¨
        detector = ImprovedXGBoostDetector(
            target_column='mean_motion',
            enable_threshold_optimization=False, # æˆ‘ä»¬æ²¡æœ‰æä¾›éªŒè¯é›†æ ‡ç­¾ï¼Œè®©å…¶è‡ªåŠ¨ä¼˜åŒ–
            enable_temporal_clustering=True,
            satellite_type='auto',
            ultra_deep=True
        )
        
        # 4. è®­ç»ƒæ¨¡å‹
        print("   ğŸ”§ è®­ç»ƒEnhanced XGBoostæ£€æµ‹å™¨...")
        #    æ¨¡å‹å°†åªä½¿ç”¨ normal_train_data è¿›è¡Œè®­ç»ƒ
        #    åœ¨å…¶å†…éƒ¨ï¼Œfitæ–¹æ³•ä¼šè‡ªåŠ¨åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†ç”¨äºearly stopping
        detector.fit(
            train_features=normal_train_data,
            satellite_name="Fengyun-4A",
            verbose=True
        )
        
        # 5. åœ¨ç‹¬ç«‹çš„æµ‹è¯•é›†ä¸Šæ£€æµ‹å¼‚å¸¸
        print("   ğŸ” æ£€æµ‹æµ‹è¯•é›†å¼‚å¸¸...")
        anomaly_indices, anomaly_scores = detector.detect_anomalies(test_data, return_scores=True)
        anomaly_timestamps = test_data.index[anomaly_indices]
        
        print(f"âœ… Enhanced XGBoostæ£€æµ‹å®Œæˆ:")
        print(f"   æ£€æµ‹åˆ° {len(anomaly_timestamps)} ä¸ªå¼‚å¸¸ç‚¹")
        if len(test_data) > 0:
            print(f"   å¼‚å¸¸æ¯”ä¾‹: {len(anomaly_timestamps)/len(test_data)*100:.2f}%")
        
        return anomaly_timestamps, anomaly_scores, test_data, detector
        
    except Exception as e:
        print(f"âŒ Enhanced XGBoostæ£€æµ‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None, None


# =====================================================================
# ä»»åŠ¡3ï¼šç”¨æœºåŠ¨æ—¥å¿—æ£€æŸ¥å‡†ç¡®æ€§
# =====================================================================
def check_enhanced_xgboost_accuracy(anomaly_timestamps, test_data, maneuver_times):
    """ä»»åŠ¡3ï¼šæ£€æŸ¥Enhanced XGBoostå‡†ç¡®æ€§"""
    print("\nğŸ“Š ä»»åŠ¡3ï¼šæ£€æŸ¥Enhanced XGBoostå‡†ç¡®æ€§")
    print("-" * 35)
    
    if anomaly_timestamps is None or len(maneuver_times) == 0:
        print("âš ï¸ æ²¡æœ‰æ£€æµ‹ç»“æœæˆ–æœºåŠ¨æ—¥å¿—ï¼Œè·³è¿‡å‡†ç¡®æ€§æ£€æŸ¥")
        return None
    
    # åˆ›å»ºæµ‹è¯•é›†çš„çœŸå®æ ‡ç­¾
    test_true_labels = create_labels_for_split(test_data.index, maneuver_times, window=timedelta(days=1))
    
    # åˆ›å»ºé¢„æµ‹æ ‡ç­¾
    test_pred_labels = pd.Series(0, index=test_data.index)
    for anomaly_time in anomaly_timestamps:
        if anomaly_time in test_pred_labels.index:
            test_pred_labels.loc[anomaly_time] = 1
    
    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    try:
        from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
        
        precision = precision_score(test_true_labels, test_pred_labels, zero_division=0)
        recall = recall_score(test_true_labels, test_pred_labels, zero_division=0)
        f1 = f1_score(test_true_labels, test_pred_labels, zero_division=0)
        
        # æ··æ·†çŸ©é˜µ
        tn, fp, fn, tp = confusion_matrix(test_true_labels, test_pred_labels).ravel()
        
        print(f"âœ… Enhanced XGBoostæ€§èƒ½:")
        print(f"   ç²¾ç¡®ç‡(Precision): {precision:.3f}")
        print(f"   å¬å›ç‡(Recall): {recall:.3f}")
        print(f"   F1åˆ†æ•°: {f1:.3f}")
        print(f"   çœŸæ­£ä¾‹(TP): {tp}, å‡æ­£ä¾‹(FP): {fp}")
        print(f"   çœŸè´Ÿä¾‹(TN): {tn}, å‡è´Ÿä¾‹(FN): {fn}")
        
        return {'precision': precision, 'recall': recall, 'f1': f1, 'tp': tp, 'fp': fp, 'fn': fn}
        
    except Exception as e:
        print(f"âŒ å‡†ç¡®æ€§è®¡ç®—å¤±è´¥: {e}")
        return None

# =====================================================================
# ä»»åŠ¡4ï¼šç²’å­æ»¤æ³¢æ–¹æ³•ï¼ˆä¿æŒä¸å˜ï¼‰
# =====================================================================
def particle_filter_detection(enhanced_data, maneuver_times):
    """ä»»åŠ¡4ï¼šç²’å­æ»¤æ³¢æ–¹æ³•æ£€æµ‹"""
    print("\nğŸ”¬ ä»»åŠ¡4ï¼šç²’å­æ»¤æ³¢æ£€æµ‹")
    print("-" * 22)
    
    try:
        # ä½¿ç”¨åŸºç¡€ç‰¹å¾è¿›è¡Œç²’å­æ»¤æ³¢
        base_cols = ['mean_motion', 'eccentricity', 'inclination']
        available_cols = [col for col in base_cols if col in enhanced_data.columns]
        
        if not available_cols:
            print(f"âŒ æ²¡æœ‰æ‰¾åˆ°åŸºç¡€ç‰¹å¾åˆ—")
            return None, None, None
        
        data_matrix = enhanced_data[available_cols].values
        
        # ç®€åŒ–çš„ç²’å­æ»¤æ³¢å™¨
        print("   ğŸ”§ è¿è¡Œç²’å­æ»¤æ³¢å™¨...")
        
        window_size = 7
        anomaly_scores = []
        anomaly_indices = []
        
        for i in range(window_size, len(data_matrix)):
            window_data = data_matrix[i-window_size:i]
            current_point = data_matrix[i]
            
            window_mean = np.mean(window_data, axis=0)
            window_std = np.std(window_data, axis=0)
            
            z_scores = np.abs(current_point - window_mean) / (window_std + 1e-8)
            combined_score = np.mean(z_scores)
            
            anomaly_scores.append(combined_score)
            
            # è°ƒæ•´é˜ˆå€¼ä»¥å‡å°‘è¯¯æŠ¥
            if combined_score > 2.5:  # æé«˜é˜ˆå€¼
                anomaly_indices.append(i)
        
        pf_anomaly_timestamps = enhanced_data.index[anomaly_indices]
        
        print(f"âœ… ç²’å­æ»¤æ³¢æ£€æµ‹å®Œæˆ:")
        print(f"   æ£€æµ‹åˆ° {len(pf_anomaly_timestamps)} ä¸ªå¼‚å¸¸ç‚¹")
        print(f"   å¼‚å¸¸æ¯”ä¾‹: {len(pf_anomaly_timestamps)/len(enhanced_data)*100:.2f}%")
        
        # æ£€æŸ¥å‡†ç¡®æ€§
        if len(maneuver_times) > 0:
            print("\nğŸ“Š ç²’å­æ»¤æ³¢å‡†ç¡®æ€§æ£€æŸ¥:")
            
            true_labels = create_labels_for_split(enhanced_data.index, maneuver_times, window=timedelta(days=1))
            pred_labels = pd.Series(0, index=enhanced_data.index)
            
            for anomaly_time in pf_anomaly_timestamps:
                if anomaly_time in pred_labels.index:
                    pred_labels.loc[anomaly_time] = 1
            
            try:
                from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
                
                precision = precision_score(true_labels, pred_labels, zero_division=0)
                recall = recall_score(true_labels, pred_labels, zero_division=0)
                f1 = f1_score(true_labels, pred_labels, zero_division=0)
                tn, fp, fn, tp = confusion_matrix(true_labels, pred_labels).ravel()
                
                print(f"   ç²¾ç¡®ç‡(Precision): {precision:.3f}")
                print(f"   å¬å›ç‡(Recall): {recall:.3f}")
                print(f"   F1åˆ†æ•°: {f1:.3f}")
                print(f"   çœŸæ­£ä¾‹(TP): {tp}, å‡æ­£ä¾‹(FP): {fp}")
                print(f"   çœŸè´Ÿä¾‹(TN): {tn}, å‡è´Ÿä¾‹(FN): {fn}")
                
                return pf_anomaly_timestamps, anomaly_scores, {'precision': precision, 'recall': recall, 'f1': f1}
                
            except Exception as e:
                print(f"âš ï¸ å‡†ç¡®æ€§è®¡ç®—å¤±è´¥: {e}")
                return pf_anomaly_timestamps, anomaly_scores, None
        
        return pf_anomaly_timestamps, anomaly_scores, None
        
    except Exception as e:
        print(f"âŒ ç²’å­æ»¤æ³¢æ£€æµ‹å¤±è´¥: {e}")
        return None, None, None

# =====================================================================
# ä¸»å‡½æ•°
# =====================================================================
def main():
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡"""
    print(f"ğŸ“‚ å·¥ä½œç›®å½•: {project_root}")
    
    # ä»»åŠ¡1ï¼šè¯»å–æ•°æ®
    tle_data, maneuver_times = load_data()
    if tle_data is None:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼Œä»»åŠ¡ç»ˆæ­¢")
        return
    
    # ç‰¹å¾å·¥ç¨‹
    enhanced_data = create_enhanced_features(tle_data)
    if enhanced_data is None:
        print("âŒ ç‰¹å¾å·¥ç¨‹å¤±è´¥ï¼Œä»»åŠ¡ç»ˆæ­¢")
        return
    
    # ä»»åŠ¡2ï¼šEnhanced XGBoostæ£€æµ‹
    xgb_anomaly_timestamps, xgb_scores, test_data, detector = enhanced_xgboost_detection(
        enhanced_data, maneuver_times
    )
    
    # ä»»åŠ¡3ï¼šæ£€æŸ¥Enhanced XGBoostå‡†ç¡®æ€§
    xgb_performance = None
    if xgb_anomaly_timestamps is not None and test_data is not None:
        xgb_performance = check_enhanced_xgboost_accuracy(
            xgb_anomaly_timestamps, test_data, maneuver_times
        )
    
    # ä»»åŠ¡4ï¼šç²’å­æ»¤æ³¢æ–¹æ³•
    pf_anomaly_timestamps, pf_scores, pf_performance = particle_filter_detection(
        enhanced_data, maneuver_times
    )
    
    # æ€»ç»“å¯¹æ¯”
    print("\n" + "=" * 60)
    print("ğŸ“Š æ€»ç»“å¯¹æ¯”")
    print("=" * 60)
    
    print(f"ğŸ” æ•°æ®æ¦‚å†µ:")
    print(f"   TLEè®°å½•æ•°: {len(tle_data)}")
    print(f"   å¢å¼ºç‰¹å¾è®°å½•æ•°: {len(enhanced_data)}")
    print(f"   æœºåŠ¨äº‹ä»¶æ•°: {len(maneuver_times)}")
    
    if xgb_anomaly_timestamps is not None and test_data is not None:
        print(f"\nğŸ¤– Enhanced XGBoostç»“æœ:")
        print(f"   æµ‹è¯•é›†å¤§å°: {len(test_data)}")
        print(f"   æ£€æµ‹å¼‚å¸¸æ•°: {len(xgb_anomaly_timestamps)}")
        if xgb_performance:
            print(f"   F1åˆ†æ•°: {xgb_performance['f1']:.3f}")
            print(f"   ç²¾ç¡®ç‡: {xgb_performance['precision']:.3f}")
            print(f"   å¬å›ç‡: {xgb_performance['recall']:.3f}")
    
    if pf_anomaly_timestamps is not None:
        print(f"\nğŸ”¬ ç²’å­æ»¤æ³¢ç»“æœ:")
        print(f"   æ£€æµ‹å¼‚å¸¸æ•°: {len(pf_anomaly_timestamps)}")
        if pf_performance:
            print(f"   F1åˆ†æ•°: {pf_performance['f1']:.3f}")
            print(f"   ç²¾ç¡®ç‡: {pf_performance['precision']:.3f}")
            print(f"   å¬å›ç‡: {pf_performance['recall']:.3f}")
    
    # æ¯”è¾ƒæ€§èƒ½
    if xgb_performance and pf_performance:
        print(f"\nğŸ† æ€§èƒ½å¯¹æ¯”:")
        if xgb_performance['f1'] > pf_performance['f1']:
            print(f"   Enhanced XGBoostæ›´å¥½: F1={xgb_performance['f1']:.3f} vs {pf_performance['f1']:.3f}")
        elif pf_performance['f1'] > xgb_performance['f1']:
            print(f"   ç²’å­æ»¤æ³¢æ›´å¥½: F1={pf_performance['f1']:.3f} vs {xgb_performance['f1']:.3f}")
        else:
            print(f"   æ€§èƒ½ç›¸è¿‘: F1={xgb_performance['f1']:.3f}")
    
    print(f"\nâœ… Enhanced XGBoostä»»åŠ¡å®Œæˆï¼")

if __name__ == "__main__":
    main()