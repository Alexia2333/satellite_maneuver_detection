# scripts/integrated_kfold_task.py
"""
ã€æœ€ç»ˆé›†æˆç‰ˆ - V3 / ç­–ç•¥2ã€‘
é‡‡ç”¨åˆ†ä½æ•°é˜ˆå€¼æ³•ï¼Œå¹¶è¿›è¡Œä¸¥æ ¼çš„æ— ç›‘ç£KæŠ˜äº¤å‰éªŒè¯ã€‚
"""

import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
from sklearn.model_selection import TimeSeriesSplit

warnings.filterwarnings('ignore')

# --- è·¯å¾„è®¾ç½® ---
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)
sys.path.insert(0, os.path.join(project_root, 'src'))

# --- å¯¼å…¥æ¨¡å— ---
try:
    from src.data.loader import SatelliteDataLoader
    from src.data.feature_engineer import EnhancedSatelliteFeatureEngineer
    from src.models.hybrid.enhanced_xgboost_detector import ImprovedXGBoostDetector
    from src.models.hybrid.xgboost_detector import create_labels_for_split
except ImportError as e:
    print(f"âŒ æ— æ³•å¯¼å…¥æ¨¡å—: {e}")
    sys.exit(1)

# --- æ€§èƒ½è®¡ç®—å‡½æ•° (ä¸å˜) ---
def calculate_performance(y_true, y_pred):
    from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
    precision = precision_score(y_true, y_pred, zero_division=0)
    recall = recall_score(y_true, y_pred, zero_division=0)
    f1 = f1_score(y_true, y_pred, zero_division=0)
    if len(np.unique(y_true)) > 1 and len(np.unique(y_pred)) > 1: tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    else:
        tp = np.sum((y_true == 1) & (y_pred == 1)); fp = np.sum((y_true == 0) & (y_pred == 1))
        fn = np.sum((y_true == 1) & (y_pred == 0)); tn = np.sum((y_true == 0) & (y_pred == 0))
    return {'precision': precision, 'recall': recall, 'f1': f1, 'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn}

# --- ä¸»æ‰§è¡Œå‡½æ•° ---
def main():
    SATELLITE_NAME = "Fengyun-4A"
    TARGET_COLUMN = 'mean_motion'
    N_SPLITS = 5

    print(f"ğŸš€ å¼€å§‹ä¸ºå«æ˜Ÿ {SATELLITE_NAME} æ‰§è¡Œæ— ç›‘ç£KæŠ˜äº¤å‰éªŒè¯ä»»åŠ¡ (ç­–ç•¥: åˆ†ä½æ•°é˜ˆå€¼)")
    print("=" * 60)

    # 1. æ•°æ®åŠ è½½
    print(" STEP 1: åŠ è½½åŸå§‹æ•°æ®")
    loader = SatelliteDataLoader(data_dir="data")
    tle_data, maneuver_times = loader.load_satellite_data(SATELLITE_NAME)
    if tle_data is None: return
    print(f"âœ… åŠ è½½å®Œæˆ: {len(tle_data)} æ¡è®°å½•, {len(maneuver_times)} æ¬¡æœºåŠ¨ã€‚")

    # 2. ç‰¹å¾å·¥ç¨‹
    print("\n STEP 2: åˆ›å»ºå¢å¼ºç‰¹å¾")
    features_input_data = tle_data.set_index('epoch').sort_index()
    engineer = EnhancedSatelliteFeatureEngineer(
        target_column=TARGET_COLUMN, additional_columns=['eccentricity', 'inclination'], satellite_type='GEO')
    engineer.fit(features_input_data, satellite_name=SATELLITE_NAME)
    features_df = engineer.transform(features_input_data)
    
    # 3. ä¿®æ­£å­¦ä¹ ç›®æ ‡
    print("\n STEP 3: ä¿®æ­£å­¦ä¹ ç›®æ ‡ä¸ºâ€œå˜åŒ–é‡â€")
    features_df['target'] = features_df[TARGET_COLUMN].diff().shift(-1)
    final_data = features_df.dropna()
    print(f"âœ… æœ€ç»ˆæ•°æ®é›†å¤§å°: {len(final_data)}")

    # 4. KæŠ˜äº¤å‰éªŒè¯
    print(f"\n STEP 4: åˆå§‹åŒ– {N_SPLITS}-æŠ˜ æ—¶é—´åºåˆ—äº¤å‰éªŒè¯")
    tscv = TimeSeriesSplit(n_splits=N_SPLITS)
    results = []
    
    print("-" * 60)
    for fold, (train_index, test_index) in enumerate(tscv.split(final_data)):
        print(f"ğŸ”„ [ç¬¬ {fold + 1}/{N_SPLITS} æŠ˜]")
        train_data = final_data.iloc[train_index]; test_data = final_data.iloc[test_index]
        print(f"   è®­ç»ƒæ•°æ®: {len(train_data)} æ¡, æµ‹è¯•æ•°æ®: {len(test_data)} æ¡")

        # ã€æ ¸å¿ƒä¿®æ”¹ã€‘åˆå§‹åŒ–æ¨¡å‹æ—¶ä½¿ç”¨ quantile å‚æ•°
        detector = ImprovedXGBoostDetector(
            target_column=TARGET_COLUMN,
            satellite_type='auto',
            ultra_deep=True,
            threshold_quantile=0.999 # <--- åœ¨æ­¤è°ƒæ•´åˆ†ä½æ•°ï¼Œè¿™æ˜¯ç°åœ¨çš„å…³é”®è°ƒä¼˜å‚æ•°
        )

        print("   â³ æ­£åœ¨è®­ç»ƒ...")
        detector.fit(train_features=train_data, satellite_name=SATELLITE_NAME, verbose=True)
        
        print("   ğŸ¯ æ­£åœ¨é¢„æµ‹...")
        anomaly_indices, _ = detector.detect_anomalies(test_data, return_scores=True)
        anomaly_timestamps = test_data.index[anomaly_indices]

        # éªŒè¯æ€§èƒ½
        y_true = create_labels_for_split(test_data.index, maneuver_times, window=timedelta(days=1))
        y_pred = pd.Series(0, index=test_data.index); y_pred.loc[anomaly_timestamps] = 1

        if y_true.sum() > 0:
            performance = calculate_performance(y_true, y_pred)
            results.append(performance)
            print(f"   ğŸ“Š ç»“æœ: F1={performance['f1']:.3f}, P={performance['precision']:.3f}, R={performance['recall']:.3f} (TP:{performance['tp']}, FP:{performance['fp']}, FN:{performance['fn']})")
        else:
            print("   âš ï¸ å½“å‰æµ‹è¯•æŠ˜æ— æœºåŠ¨äº‹ä»¶ï¼Œè·³è¿‡è¯„ä¼°ã€‚")
        print("-" * 60)

    # æ±‡æ€»æœ€ç»ˆç»“æœ
    if not results:
        print("âŒ æœªèƒ½åœ¨ä»»ä½•æŠ˜ä¸­å®Œæˆæœ‰æ•ˆçš„æ€§èƒ½è¯„ä¼°ã€‚"); return

    print("\n" + "=" * 60); print("ğŸ† KæŠ˜äº¤å‰éªŒè¯æœ€ç»ˆæ€§èƒ½æ€»ç»“"); print("=" * 60)
    results_df = pd.DataFrame(results)
    mean_perf = results_df.mean(); std_perf = results_df.std()
    print(f"åŸºäº {len(results)} ä¸ªæœ‰æ•ˆæŠ˜çš„å¹³å‡æ€§èƒ½:")
    print(f"   - F1åˆ†æ•°    : {mean_perf['f1']:.3f} Â± {std_perf['f1']:.3f}")
    print(f"   - ç²¾ç¡®ç‡(P) : {mean_perf['precision']:.3f} Â± {std_perf['precision']:.3f}")
    print(f"   - å¬å›ç‡(R) : {mean_perf['recall']:.3f} Â± {std_perf['recall']:.3f}")
    print("\næ··æ·†çŸ©é˜µé¡¹ (å¹³å‡å€¼):")
    print(f"   - çœŸæ­£ä¾‹ (TP): {mean_perf['tp']:.1f}, å‡æ­£ä¾‹ (FP): {mean_perf['fp']:.1f}, å‡è´Ÿä¾‹ (FN): {mean_perf['fn']:.1f}")

if __name__ == "__main__":
    main()