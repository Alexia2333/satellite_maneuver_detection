# scripts/fy4a_unsupervised_detection.py
"""
é£äº‘4Aå«æ˜Ÿæ— ç›‘ç£æœºåŠ¨æ£€æµ‹å®éªŒ

è¯¥è„šæœ¬å®ç°äº†ä»æœ‰ç›‘ç£å­¦ä¹ åˆ°æ— ç›‘ç£å­¦ä¹ çš„è½¬æ¢ï¼Œå¹¶åœ¨é£äº‘4Aå«æ˜Ÿæ•°æ®ä¸Šè¿›è¡ŒéªŒè¯ã€‚
"""

import os
import sys
import pandas as pd
import numpy as np
from datetime import timedelta
import matplotlib.pyplot as plt
import seaborn as sns

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from src.data.loader import SatelliteDataLoader
from src.data.feature_engineer import create_drift_enhanced_features
from src.models.unsupervised.xgboost_unsupervised_adapter import (
    XGBoostUnsupervisedAdapter, create_unsupervised_detector
)
from src.evaluation.visualization import plot_detection_results
from src.evaluation.reporting import save_detection_report

# å¯¼å…¥æœ‰ç›‘ç£å­¦ä¹ çš„æ ‡ç­¾åˆ›å»ºå‡½æ•°ï¼ˆç”¨äºè¯„ä¼°ï¼‰
try:
    from src.models.hybrid.xgboost_detector import create_labels_for_split
except ImportError:
    def create_labels_for_split(indices, maneuver_times, window):
        """ç®€åŒ–çš„æ ‡ç­¾åˆ›å»ºå‡½æ•°"""
        labels = pd.Series(0, index=indices)
        for maneuver_time in maneuver_times:
            mask = (indices >= maneuver_time - window) & (indices <= maneuver_time + window)
            labels[mask] = 1
        return labels


class UnsupervisedExperiment:
    """æ— ç›‘ç£æœºåŠ¨æ£€æµ‹å®éªŒç±»"""
    
    def __init__(self, config):
        self.config = config
        self.loader = SatelliteDataLoader(data_dir=config['data_dir'])
        self.detector = None
        self.results = {}
        
    def run_experiment(self):
        """è¿è¡Œå®Œæ•´çš„æ— ç›‘ç£æ£€æµ‹å®éªŒ"""
        print("\n" + "="*60)
        print("ğŸš€ é£äº‘4Aå«æ˜Ÿæ— ç›‘ç£æœºåŠ¨æ£€æµ‹å®éªŒ")
        print("="*60)
        
        # 1. åŠ è½½æ•°æ®
        tle_data, maneuver_times = self._load_data()
        
        # 2. ç‰¹å¾å·¥ç¨‹
        enhanced_data = self._create_features(tle_data)
        
        # 3. æ•°æ®åˆ’åˆ†
        train_data, val_data, test_data = self._split_data(enhanced_data)
        

        # è¿­ä»£å¼è®­ç»ƒæµç¨‹
        print("\n\n--- é˜¶æ®µä¸€ï¼šåˆå§‹è®­ç»ƒä¸ç²—ç­› ---")
        initial_config = self.config.copy()
        initial_config['threshold_method'] = 'percentile'
        initial_config['threshold_percentile'] = 99.0 # å¯ä»¥è®¾ç½®ä¸€ä¸ªç›¸å¯¹å®½æ¾çš„ç™¾åˆ†ä½

        initial_detector = create_unsupervised_detector(initial_config)
        initial_detector.fit(train_data, target_column='target')

        # åœ¨è®­ç»ƒé›†ä¸Šæ‰¾å‡ºç–‘ä¼¼å¼‚å¸¸ç‚¹
        suspected_anomalies_indices, _ = initial_detector.detect_anomalies(train_data, return_scores=True)
    
        print(f"\n   ğŸ§¹ åœ¨è®­ç»ƒé›†ä¸­å‘ç° {len(suspected_anomalies_indices)} ä¸ªç–‘ä¼¼å¼‚å¸¸ç‚¹ï¼Œå°†ç”¨äºå‡€åŒ–æ•°æ®ã€‚")

        # ---- é˜¶æ®µäºŒï¼šå‡€åŒ–æ•°æ®å¹¶è¿›è¡Œæœ€ç»ˆè®­ç»ƒ ----
        print("\n\n--- é˜¶æ®µäºŒï¼šå‡€åŒ–æ•°æ®ä¸æœ€ç»ˆè®­ç»ƒ ---")
    
        # ä»è®­ç»ƒæ•°æ®ä¸­ç§»é™¤ç¬¬ä¸€é˜¶æ®µæ‰¾åˆ°çš„å¼‚å¸¸ç‚¹
        if len(suspected_anomalies_indices) > 0:
            clean_train_data = train_data.drop(suspected_anomalies_indices)
            print(f"   åŸå§‹è®­ç»ƒæ ·æœ¬: {len(train_data)}, å‡€åŒ–åæ ·æœ¬: {len(clean_train_data)}")
        else:
            clean_train_data = train_data
            print("   æœªå‘ç°å¯å‡€åŒ–çš„å¼‚å¸¸ç‚¹ï¼Œä½¿ç”¨åŸå§‹æ•°æ®è¿›è¡Œæœ€ç»ˆè®­ç»ƒã€‚")












        # 4. è®­ç»ƒæ— ç›‘ç£æ£€æµ‹å™¨
        self._train_unsupervised_detector(clean_train_data)
        
        # 5. åœ¨éªŒè¯é›†ä¸Šä¼˜åŒ–å‚æ•°
        #self._optimize_on_validation(val_data, maneuver_times)
        
        # 6. åœ¨æµ‹è¯•é›†ä¸Šæ£€æµ‹
        anomalies = self._detect_on_test(test_data)
        
        # 7. è¯„ä¼°ç»“æœï¼ˆå¦‚æœæœ‰çœŸå®æ ‡ç­¾ï¼‰
        metrics = self._evaluate_results(test_data, anomalies, maneuver_times)
        
        # 8. å¯è§†åŒ–å’ŒæŠ¥å‘Š
        self._visualize_results(test_data, anomalies, maneuver_times)
        self._save_report(metrics, anomalies)
        
        print("\nâœ… å®éªŒå®Œæˆï¼")
        return self.results
    
    def _load_data(self):
        """åŠ è½½å«æ˜Ÿæ•°æ®"""
        print("\nğŸ“ åŠ è½½æ•°æ®...")
        tle_data, maneuver_times = self.loader.load_satellite_data(
            self.config['satellite_name']
        )
        print(f"   - TLEè®°å½•æ•°: {len(tle_data)}")
        print(f"   - å·²çŸ¥æœºåŠ¨æ•°: {len(maneuver_times)}")
        return tle_data, maneuver_times
    
    def _create_features(self, tle_data):
        """åˆ›å»ºå¢å¼ºç‰¹å¾"""
        print("\nğŸ”§ ç‰¹å¾å·¥ç¨‹...")
        enhanced_data = create_drift_enhanced_features(
            tle_data, 
            scaling_factor=self.config['target_scaling_factor']
        )
        print(f"   - ç‰¹å¾æ•°: {len(enhanced_data.columns)}")
        print(f"   - æœ‰æ•ˆæ ·æœ¬: {len(enhanced_data)}")
        return enhanced_data
    
    def _split_data(self, enhanced_data):
        """åˆ’åˆ†æ•°æ®é›†"""
        print("\nğŸ“Š æ•°æ®åˆ’åˆ†...")
        n = len(enhanced_data)
        train_end = int(n * self.config['train_ratio'])
        val_end = int(n * (self.config['train_ratio'] + self.config['val_ratio']))
        
        train_data = enhanced_data.iloc[:train_end]
        val_data = enhanced_data.iloc[train_end:val_end]
        test_data = enhanced_data.iloc[val_end:]
        
        print(f"   - è®­ç»ƒé›†: {len(train_data)} ({self.config['train_ratio']*100:.0f}%)")
        print(f"   - éªŒè¯é›†: {len(val_data)} ({self.config['val_ratio']*100:.0f}%)")
        print(f"   - æµ‹è¯•é›†: {len(test_data)} ({self.config['test_ratio']*100:.0f}%)")
        
        return train_data, val_data, test_data
    
    def _train_unsupervised_detector(self, train_data):
        """è®­ç»ƒæ— ç›‘ç£æ£€æµ‹å™¨"""
        print("\nğŸ¤– è®­ç»ƒæ— ç›‘ç£æ£€æµ‹å™¨...")
        
        # åˆ›å»ºæ£€æµ‹å™¨
        detector_config = {
            'threshold_method': self.config['threshold_method'],
            'threshold_factor': self.config['threshold_factor'],
            'percentile': self.config['threshold_percentile'],
            'min_segment_size': self.config['min_segment_size'],
            'max_gap_days': self.config['max_gap_days'],
            'enable_drift_adjustment': self.config['enable_drift_adjustment']
        }
        
        self.detector = create_unsupervised_detector(detector_config)
        


        # å¦‚æœæœ‰é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼ŒåŠ è½½å®ƒ
        if self.config.get('pretrained_model_path'):
            self.detector.load_pretrained_model(self.config['pretrained_model_path'])
        
        # è®­ç»ƒæ£€æµ‹å™¨
        self.detector.fit(train_data, target_column='target')
        
    def _optimize_on_validation(self, val_data, maneuver_times):
        print("\nğŸ” éªŒè¯é›†å‚æ•°ä¼˜åŒ–...")
    
        # æ£€æŸ¥é˜ˆå€¼æ–¹æ³•æ˜¯å¦ä¸º 'percentile'
        if self.config.get('threshold_method') != 'percentile':
            print(f"   - å½“å‰æ–¹æ³•ä¸º '{self.config.get('threshold_method')}'ï¼Œè·³è¿‡ç™¾åˆ†ä½ä¼˜åŒ–ã€‚")
            self.results['validation_f1'] = 'N/A'
            self.results['best_threshold_percentile'] = 'N/A'
            return
    
        # å®šä¹‰è¦æµ‹è¯•çš„ç™¾åˆ†ä½èŒƒå›´
        percentiles_to_test = np.linspace(99.0, 99.95, 20)
        best_f1 = -1.0
        best_percentile = self.config.get('threshold_percentile', 99.5)
    
        # ä¿å­˜åŸå§‹æ£€æµ‹å™¨çŠ¶æ€ï¼Œä»¥ä¾¿å¾ªç¯ç»“æŸåæ¢å¤
        original_percentile = self.detector.percentile
    
        print(f"   - æ­£åœ¨ä¸º {len(percentiles_to_test)} ä¸ªä¸åŒçš„ç™¾åˆ†ä½è¯„ä¼°F1åˆ†æ•°...")
    
        # å¾ªç¯æµ‹è¯•æ¯ä¸ªç™¾åˆ†ä½
        for p in percentiles_to_test:
            self.detector.percentile = p
            self.detector._calculate_dynamic_threshold()  # æ ¹æ®æ–°ç™¾åˆ†ä½è®¡ç®—æ–°é˜ˆå€¼
    
            anomalies, _ = self.detector.detect_anomalies(val_data, return_scores=True)
            val_labels = create_labels_for_split(val_data.index, maneuver_times, timedelta(days=1))
    
            if val_labels.sum() == 0:
                continue
    
            pred_labels = pd.Series(0, index=val_data.index)
            if len(anomalies) > 0:
                # ç¡®ä¿å¼‚å¸¸ç‚¹åœ¨éªŒè¯é›†çš„ç´¢å¼•å†…
                valid_anomalies = [a for a in anomalies if a in pred_labels.index]
                if valid_anomalies:
                    pred_labels.loc[valid_anomalies] = 1
    
            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            tp = ((pred_labels == 1) & (val_labels == 1)).sum()
            fp = ((pred_labels == 1) & (val_labels == 0)).sum()
            fn = ((pred_labels == 0) & (val_labels == 1)).sum()
    
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0
            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    
            if f1 > best_f1:
                best_f1 = f1
                best_percentile = p
    
        # åº”ç”¨åœ¨éªŒè¯é›†ä¸Šæ‰¾åˆ°çš„æœ€ä½³å‚æ•°
        self.detector.percentile = best_percentile
        self.detector._calculate_dynamic_threshold()
    
        print(f"   - æœ€ä½³ç™¾åˆ†ä½: {best_percentile:.4f}")
        print(f"   - éªŒè¯é›†æœ€ä½³F1: {best_f1:.3f}")
    
        # å°†ç»“æœå­˜å…¥å­—å…¸
        self.results['best_threshold_percentile'] = best_percentile
        self.results['validation_f1'] = best_f1
        
    def _detect_on_test(self, test_data):
        """åœ¨æµ‹è¯•é›†ä¸Šæ£€æµ‹å¼‚å¸¸"""
        print("\nğŸ¯ æµ‹è¯•é›†æ£€æµ‹...")
        
        anomalies, scores = self.detector.detect_anomalies(
            test_data, 
            return_scores=True
        )
        
        print(f"   - æ£€æµ‹åˆ°å¼‚å¸¸ç‚¹: {len(anomalies)}")
        print(f"   - å¼‚å¸¸æ¯”ä¾‹: {len(anomalies)/len(test_data)*100:.2f}%")
        
        self.results['test_anomalies'] = anomalies
        self.results['anomaly_scores'] = scores
        
        return anomalies
    
    def _evaluate_results(self, test_data, anomalies, maneuver_times):
        """è¯„ä¼°æ£€æµ‹ç»“æœ"""
        print("\nğŸ“ˆ è¯„ä¼°ç»“æœ...")

        # å¦‚æœæ²¡æœ‰æä¾›çœŸå®çš„æœºåŠ¨æ—¶é—´ï¼Œåˆ™è·³è¿‡ä¼ ç»Ÿè¯„ä¼°
        if not maneuver_times or len(maneuver_times) == 0:
            print("   - æœªæä¾›çœŸå®æœºåŠ¨æ•°æ®ï¼Œè·³è¿‡ç²¾ç¡®ç‡/å¬å›ç‡è¯„ä¼°ã€‚")
            print(f"   - å°†æ‰€æœ‰ {len(anomalies)} ä¸ªæ£€æµ‹åˆ°çš„å¼‚å¸¸ç‚¹æ ‡è®°ä¸º 'å¾…æŸ¥ç‚¹'ã€‚")
            
            # å°†æ‰€æœ‰æ£€æµ‹åˆ°çš„å¼‚å¸¸éƒ½è§†ä¸ºè¯¯æŠ¥ï¼ˆå› ä¸ºæ²¡æœ‰çœŸå®æœºåŠ¨ï¼‰
            metrics = {
                'tp': 0, 'fp': len(anomalies), 
                'tn': len(test_data) - len(anomalies), 'fn': 0,
                'precision': 0, 'recall': 0, 'f1': 0,
                'notes': "No ground truth maneuver data provided for evaluation."
            }
            self.results['test_metrics'] = metrics
            return metrics
        
        # --- å¦‚æœæœ‰çœŸå®æ•°æ®ï¼Œåˆ™æ‰§è¡Œä»¥ä¸‹åŸå§‹é€»è¾‘ ---
        print("   - å‘ç°çœŸå®æœºåŠ¨æ•°æ®ï¼Œè¿›è¡Œæ ‡å‡†è¯„ä¼°...")
        # åˆ›å»ºçœŸå®æ ‡ç­¾
        test_labels = create_labels_for_split(
            test_data.index,
            maneuver_times,
            timedelta(days=self.config['label_window_days'])
        )
        
        # åˆ›å»ºé¢„æµ‹æ ‡ç­¾
        pred_labels = pd.Series(0, index=test_data.index)
        if len(anomalies) > 0:
            # ä½¿ç”¨.unique()æ–¹æ³•ä¸ºPandasç´¢å¼•å»é‡ï¼Œç„¶åè¿›è¡Œç´¢å¼•
            unique_anomalies = anomalies.unique()
            pred_labels.loc[unique_anomalies] = 1
        
        # è®¡ç®—æŒ‡æ ‡
        tp = ((pred_labels == 1) & (test_labels == 1)).sum()
        fp = ((pred_labels == 1) & (test_labels == 0)).sum()
        tn = ((pred_labels == 0) & (test_labels == 0)).sum()
        fn = ((pred_labels == 0) & (test_labels == 1)).sum()
        
        metrics = {
            'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn,
            'precision': tp / (tp + fp) if (tp + fp) > 0 else 0,
            'recall': tp / (tp + fn) if (tp + fn) > 0 else 0,
            'f1': 0
        }
        
        if metrics['precision'] + metrics['recall'] > 0:
            metrics['f1'] = 2 * (metrics['precision'] * metrics['recall']) / \
                           (metrics['precision'] + metrics['recall'])
        
        print(f"   - ç²¾ç¡®ç‡: {metrics['precision']:.3f}")
        print(f"   - å¬å›ç‡: {metrics['recall']:.3f}")
        print(f"   - F1åˆ†æ•°: {metrics['f1']:.3f}")
        
        self.results['test_metrics'] = metrics
        return metrics
    
    def _visualize_results(self, test_data, anomalies, maneuver_times):
        """å¯è§†åŒ–æ£€æµ‹ç»“æœ"""
        print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–...")
        
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        fig, axes = plt.subplots(3, 1, figsize=(15, 12))
        
        # 1. Mean Motionæ—¶åºå›¾
        ax = axes[0]
        ax.plot(test_data.index, test_data['mean_motion'], 'b-', alpha=0.7, label='Mean Motion')
        
        if len(anomalies) > 0:
            # ä½¿ç”¨ .unique() æ¥å¤„ç†å¯èƒ½çš„é‡å¤å¼‚å¸¸ç‚¹
            unique_anomalies = anomalies.unique()
            anomaly_data = test_data.loc[unique_anomalies]
            ax.scatter(anomaly_data.index, anomaly_data['mean_motion'], 
                      color='red', s=50, alpha=0.8, label='Detected Anomalies')
        
        # --- ä¿®æ”¹åœ¨è¿™é‡Œï¼šæ­£ç¡®çš„å›¾ä¾‹å¤„ç†æ–¹å¼ ---
        # ä»…å½“æœ‰çœŸå®æœºåŠ¨æ•°æ®æ—¶æ‰ç»˜åˆ¶æ ‡è®°
        if maneuver_times and len(maneuver_times) > 0:
            # æ ‡è®°åªåœ¨ç¬¬ä¸€æ¬¡ç»˜åˆ¶æ—¶æ·»åŠ ï¼Œä»¥é¿å…å›¾ä¾‹é‡å¤
            first_maneuver_plotted = False
            for maneuver_time in maneuver_times:
                if test_data.index[0] <= maneuver_time <= test_data.index[-1]:
                    if not first_maneuver_plotted:
                        ax.axvline(x=maneuver_time, color='green', linestyle='--', label='True Maneuvers')
                        first_maneuver_plotted = True
                    else:
                        ax.axvline(x=maneuver_time, color='green', linestyle='--')
        
        ax.set_xlabel('Time')
        ax.set_ylabel('Mean Motion')
        ax.set_title('Mean Motion and Detected Anomalies')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 2. å¼‚å¸¸åˆ†æ•°åˆ†å¸ƒ
        ax = axes[1]
        if 'anomaly_scores' in self.results:
            scores = self.results['anomaly_scores']
            ax.hist(scores, bins=50, alpha=0.7, color='blue', edgecolor='black')
            ax.axvline(x=self.detector.dynamic_threshold, color='red', 
                      linestyle='--', linewidth=2, label=f'Threshold: {self.detector.dynamic_threshold:.4f}')
            ax.set_xlabel('Anomaly Score (Residuals)')
            ax.set_ylabel('Frequency')
            ax.set_title('Anomaly Score Distribution')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        # 3. æ¼‚ç§»ç‰¹å¾ä¸å¼‚å¸¸çš„å…³ç³»
        # 3. æ¼‚ç§»ç‰¹å¾ä¸å¼‚å¸¸çš„å…³ç³»
        ax = axes[2]
        drift_features = [col for col in test_data.columns if 'drift' in col]
        if drift_features:
            drift_metric = test_data[drift_features[0]]
            ax.plot(test_data.index, drift_metric, 'g-', alpha=0.7, label=drift_features[0])
            
            if len(anomalies) > 0:
                unique_anomalies = anomalies.unique()
                
                drift_metric_unique_idx = drift_metric[~drift_metric.index.duplicated(keep='first')]
                
                valid_anomalies_to_plot = unique_anomalies.intersection(drift_metric_unique_idx.index)
                
                if not valid_anomalies_to_plot.empty:
                    y_values = drift_metric_unique_idx.loc[valid_anomalies_to_plot]
                    ax.scatter(valid_anomalies_to_plot, y_values,
                               color='red', s=50, alpha=0.8, label='Anomaly Points')

            ax.set_xlabel('Time')
            ax.set_ylabel('Drift Metric')
            ax.set_title('Drift Features and Anomaly Detection')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        output_path = os.path.join(self.config['output_dir'], 'unsupervised_detection_results.png')
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"   - å¯è§†åŒ–å·²ä¿å­˜åˆ°: {output_path}")
        
    def _save_report(self, metrics, anomalies):
        """ä¿å­˜æ£€æµ‹æŠ¥å‘Š"""
        print("\nğŸ“„ ç”ŸæˆæŠ¥å‘Š...")
        
        report_path = os.path.join(self.config['output_dir'], 'unsupervised_detection_report.txt')
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("="*60 + "\n")
            f.write("é£äº‘4Aå«æ˜Ÿæ— ç›‘ç£æœºåŠ¨æ£€æµ‹æŠ¥å‘Š\n")
            f.write("="*60 + "\n\n")
            
            f.write("1. å®éªŒé…ç½®:\n")
            f.write(f"   - å«æ˜Ÿåç§°: {self.config['satellite_name']}\n")
            f.write(f"   - é˜ˆå€¼æ–¹æ³•: {self.config['threshold_method']}\n")


            if 'best_threshold_percentile' in self.results:
                f.write(f"   - æœ€ä½³é˜ˆå€¼ç™¾åˆ†ä½: {self.results['best_threshold_percentile']:.4f}\n")
            elif 'best_threshold_factor' in self.results:
                f.write(f"   - æœ€ä½³é˜ˆå€¼å› å­: {self.results['best_threshold_factor']:.2f}\n")



            f.write(f"   - æœ€å°æ®µå¤§å°: {self.config['min_segment_size']}\n")
            f.write(f"   - æœ€å¤§é—´éš”å¤©æ•°: {self.config['max_gap_days']}\n\n")
            
            f.write("2. æ£€æµ‹ç»“æœ:\n")
            f.write(f"   - æ£€æµ‹åˆ°çš„å¼‚å¸¸æ•°: {len(anomalies)}\n")
            f.write(f"   - åŠ¨æ€é˜ˆå€¼: {self.detector.dynamic_threshold:.6f}\n\n")
            
            if metrics:
                f.write("3. æ€§èƒ½è¯„ä¼°:\n")
                f.write(f"   - ç²¾ç¡®ç‡: {metrics['precision']:.3f}\n")
                f.write(f"   - å¬å›ç‡: {metrics['recall']:.3f}\n")
                f.write(f"   - F1åˆ†æ•°: {metrics['f1']:.3f}\n")
                f.write(f"   - æ··æ·†çŸ©é˜µ:\n")
                f.write(f"     TP: {metrics['tp']}, FP: {metrics['fp']}\n")
                f.write(f"     FN: {metrics['fn']}, TN: {metrics['tn']}\n\n")
            
            f.write("4. æ£€æµ‹åˆ°çš„å¼‚å¸¸æ—¶é—´ï¼ˆå‰20ä¸ªï¼‰:\n")
            for i, anomaly_time in enumerate(list(anomalies)[:20]):
                f.write(f"   {i+1:2d}. {anomaly_time}\n")
            
            if len(anomalies) > 20:
                f.write(f"   ... (è¿˜æœ‰ {len(anomalies)-20} ä¸ª)\n")
        
        print(f"   - æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")


def main():
    """ä¸»å‡½æ•°"""
    # å®éªŒé…ç½®
    config = {
        # æ•°æ®é…ç½®
        'satellite_name': 'Fengyun-4A',
        'data_dir': 'data',
        'output_dir': 'outputs/fy4a_unsupervised',
        
        # æ•°æ®åˆ’åˆ†
        'train_ratio': 0.6,
        'val_ratio': 0.2,
        'test_ratio': 0.2,
        
        # ç‰¹å¾å·¥ç¨‹
        'target_scaling_factor': 1e8,
        
        # æ— ç›‘ç£æ£€æµ‹å™¨é…ç½®
        'threshold_method': 'percentile',  # 'std', 'percentile', 'mad'
        'threshold_factor': 3.5,
        'threshold_percentile': 95,
        'min_segment_size': 1,
        'max_gap_days': 1.5,
        'enable_drift_adjustment': True,
        
        # è¯„ä¼°é…ç½®
        'label_window_days': 1,
        
        # å¯é€‰ï¼šé¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
        'pretrained_model_path': None  # å¦‚æœæœ‰çš„è¯ï¼Œå¡«å…¥è·¯å¾„
    }
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(config['output_dir'], exist_ok=True)
    
    # è¿è¡Œå®éªŒ
    experiment = UnsupervisedExperiment(config)
    results = experiment.run_experiment()
    
    # æ‰“å°æœ€ç»ˆç»“æœæ‘˜è¦
    print("\n" + "="*60)
    print("ğŸ“Š å®éªŒç»“æœæ‘˜è¦")
    print("="*60)
    
    if 'test_metrics' in results:
        metrics = results['test_metrics']
        if metrics.get('notes'):
            print(f"è¯„ä¼°å¤‡æ³¨: {metrics['notes']}")
            print(f"  - æ£€æµ‹åˆ°çš„å¾…æŸ¥ç‚¹æ•°: {metrics['fp']}")
        else:
            print(f"æœ€ç»ˆæ€§èƒ½:")
            print(f"  - ç²¾ç¡®ç‡: {metrics['precision']:.3f}")
            print(f"  - å¬å›ç‡: {metrics['recall']:.3f}")
            print(f"  - F1åˆ†æ•°: {metrics['f1']:.3f}")
    
    print(f"\néªŒè¯é›†æœ€ä½³F1: {results.get('validation_f1', 'N/A')}")
    print(f"æœ€ä½³é˜ˆå€¼å› å­: {results.get('best_threshold_factor', 'N/A')}")
    
    return results


if __name__ == "__main__":
    main()