# src/data/feature_engineer.py

import pandas as pd
import numpy as np
from typing import List, Optional
from scipy import stats

class SatelliteFeatureEngineer:
    def __init__(self, target_column: str = 'mean_motion', additional_columns: Optional[List[str]] = None,
                 lag_features: List[int] = [1, 2, 3, 5, 7, 14], rolling_windows: List[int] = [7, 14, 30]):
        self.target_column = target_column
        self.additional_columns = additional_columns or []
        self.all_process_cols = [self.target_column] + self.additional_columns
        self.lag_features = lag_features
        self.rolling_windows = rolling_windows

    def fit(self, data: pd.DataFrame) -> 'SatelliteFeatureEngineer':
        return self

    def transform(self, data: pd.DataFrame) -> pd.DataFrame:
        features_df = data.copy()
        for col in self.all_process_cols:
            features_df = self._create_base_features_for_col(features_df, col)
        return features_df

    def _create_base_features_for_col(self, df: pd.DataFrame, col_name: str) -> pd.DataFrame:
        for lag in self.lag_features:
            df[f'{col_name}_lag_{lag}'] = df[col_name].shift(lag)
        for window in self.rolling_windows:
            rolling = df[col_name].rolling(window=window, min_periods=1)
            df[f'{col_name}_rolling_mean_{window}'] = rolling.mean()
            df[f'{col_name}_rolling_std_{window}'] = rolling.std()
        df[f'{col_name}_diff_1'] = df[col_name].diff(1)
        return df

    def prepare_target_features(self, df: pd.DataFrame, forecast_horizon: int = 1) -> pd.DataFrame:
        result_df = df.copy()
        result_df['target'] = result_df[self.target_column].shift(-forecast_horizon)
        return result_df


class EnhancedSatelliteFeatureEngineer:
    def __init__(self, target_column: str = 'mean_motion', additional_columns: Optional[List[str]] = None,
                 lag_features: List[int] = [1, 2, 3, 5, 7, 14, 21, 30], 
                 rolling_windows: List[int] = [3, 7, 14, 30, 60],
                 satellite_type: str = 'auto'):
        self.target_column = target_column
        self.additional_columns = additional_columns or []
        self.all_process_cols = [self.target_column] + self.additional_columns
        self.lag_features = lag_features
        self.rolling_windows = rolling_windows
        self.satellite_type = satellite_type
        self.global_stats = {}

    def fit(self, data: pd.DataFrame, satellite_name: str = None) -> 'EnhancedSatelliteFeatureEngineer':
        if self.satellite_type == 'auto':
            self.satellite_type = self._determine_satellite_type(satellite_name)
        
        self.global_stats = {}
        for col in self.all_process_cols:
            if col in data.columns:
                self.global_stats[col] = {
                    'mean': data[col].mean(), 'std': data[col].std(), 'median': data[col].median(),
                    'q25': data[col].quantile(0.25), 'q75': data[col].quantile(0.75)
                }
        return self

    def _determine_satellite_type(self, satellite_name: str) -> str:
        if satellite_name and any(name in satellite_name.lower() for name in ['fengyun', 'goes', 'meteosat']):
            return 'GEO'
        return 'LEO'

    def transform(self, data: pd.DataFrame) -> pd.DataFrame:
        features_df = data.copy()
        
        features_df = self._create_orbital_vector_features(features_df)
        self.all_process_cols = list(set(self.all_process_cols + ['e_x', 'e_y', 'i_x', 'i_y']))


        for col in self.all_process_cols:
            if col in features_df.columns:
                features_df = self._create_enhanced_features_for_col(features_df, col)
        
        features_df = self._create_cross_element_features(features_df)
        
        # This part now becomes much more important
        if self.satellite_type == 'GEO':
            features_df = self._add_geo_specific_features(features_df)
        else: # LEO
            features_df = self._add_leo_specific_features(features_df)
        
        return features_df

    def _create_enhanced_features_for_col(self, df: pd.DataFrame, col_name: str) -> pd.DataFrame:
        print(f"   -> Creating enhanced features for {col_name}...")
        
        # 1. æ»åç‰¹å¾
        for lag in self.lag_features:
            df[f'{col_name}_lag_{lag}'] = df[col_name].shift(lag)
        
        # 2. æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾
        for window in self.rolling_windows:
            rolling = df[col_name].rolling(window=window, min_periods=1)
            df[f'{col_name}_rolling_mean_{window}'] = rolling.mean()
            df[f'{col_name}_rolling_std_{window}'] = rolling.std()
            df[f'{col_name}_rolling_min_{window}'] = rolling.min()
            df[f'{col_name}_rolling_max_{window}'] = rolling.max()
            df[f'{col_name}_rolling_median_{window}'] = rolling.median()
            
            df[f'{col_name}_rolling_range_{window}'] = (
                df[f'{col_name}_rolling_max_{window}'] - df[f'{col_name}_rolling_min_{window}']
            )
            
            mean_col = f'{col_name}_rolling_mean_{window}'
            df[f'{col_name}_rolling_cv_{window}'] = df[f'{col_name}_rolling_std_{window}'] / (df[mean_col] + 1e-8)
        
        # 3. å·®åˆ†ç‰¹å¾
        df[f'{col_name}_diff_1'] = df[col_name].diff(1)
        df[f'{col_name}_diff_2'] = df[col_name].diff(2)
        df[f'{col_name}_diff_7'] = df[col_name].diff(7)
        
        # 4. è¶‹åŠ¿ç‰¹å¾
        df = self._add_trend_features(df, col_name)
        
        # 5. æ³¢åŠ¨æ€§ç‰¹å¾
        df = self._add_volatility_features(df, col_name)
        
        # 6. ç›¸å¯¹ä½ç½®ç‰¹å¾
        df = self._add_relative_position_features(df, col_name)
        
        return df

    def _add_trend_features(self, df: pd.DataFrame, col_name: str) -> pd.DataFrame:
        for window in [7, 14, 30]:
            def trend_slope(x):
                if len(x) < 3:
                    return 0
                try:
                    return stats.linregress(range(len(x)), x)[0]
                except:
                    return 0
            
            df[f'{col_name}_trend_slope_{window}'] = (
                df[col_name].rolling(window, min_periods=3).apply(trend_slope, raw=False)
            )
            
            def trend_strength(x):
                if len(x) < 3:
                    return 0
                try:
                    slope, intercept, r_value, _, _ = stats.linregress(range(len(x)), x)
                    return r_value ** 2
                except:
                    return 0
            
            df[f'{col_name}_trend_strength_{window}'] = (
                df[col_name].rolling(window, min_periods=3).apply(trend_strength, raw=False)
            )
        
        return df

    def _add_volatility_features(self, df: pd.DataFrame, col_name: str) -> pd.DataFrame:
        for window in [7, 14, 30]:
            std_col = f'{col_name}_rolling_std_{window}'
            if std_col in df.columns:
                df[f'{col_name}_volatility_change_{window}'] = df[std_col].pct_change()
        
        if f'{col_name}_rolling_std_7' in df.columns and f'{col_name}_rolling_std_30' in df.columns:
            df[f'{col_name}_volatility_breakout'] = (
                df[f'{col_name}_rolling_std_7'] > df[f'{col_name}_rolling_std_30'] * 1.5
            ).astype(int)
        
        return df

    def _add_relative_position_features(self, df: pd.DataFrame, col_name: str) -> pd.DataFrame:
        if col_name in self.global_stats:
            stats_dict = self.global_stats[col_name]
            
            if stats_dict['std'] > 0:
                df[f'{col_name}_rel_to_mean'] = (df[col_name] - stats_dict['mean']) / stats_dict['std']
            df[f'{col_name}_rel_to_median'] = df[col_name] - stats_dict['median']
            
            df[f'{col_name}_above_q75'] = (df[col_name] > stats_dict['q75']).astype(int)
            df[f'{col_name}_below_q25'] = (df[col_name] < stats_dict['q25']).astype(int)
        
        return df

    def _create_cross_element_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ã€å¼ºåŒ–ç‰ˆã€‘åˆ›å»ºäº¤å‰å…ƒç´ ç‰¹å¾ï¼Œæ•æ‰å¤šç»´åº¦å…³è”"""
        print("   -> Creating enhanced cross-element features...")
        
        # ä¿ç•™åŸæœ‰ç‰¹å¾
        if 'mean_motion' in df.columns and 'eccentricity' in df.columns:
            df['mm_div_ecc'] = df['mean_motion'] / (df['eccentricity'] + 1e-8)
        
        if 'eccentricity' in df.columns and 'inclination' in df.columns:
            df['ecc_mul_inc'] = df['eccentricity'] * df['inclination']

        # --- æ–°å¢äº¤äº’ç‰¹å¾ ---

        # 1. åŠ¨èƒ½ç›¸å…³ç‰¹å¾ (ç®€åŒ–å½¢å¼)
        # mean_motion^2 æ­£æ¯”äºè½¨é“èƒ½é‡ï¼Œeccentricity^2 å…³ç³»åˆ°å½¢çŠ¶ã€‚
        # å®ƒä»¬çš„ç»„åˆå¯ä»¥åæ˜ è½¨é“èƒ½é‡å’Œå½¢çŠ¶çš„ç»¼åˆå˜åŒ–ã€‚
        if 'mean_motion' in df.columns and 'eccentricity' in df.columns:
            df['energy_shape_factor'] = (df['mean_motion']**2) * (1 - df['eccentricity']**2)

        # 2. è½¨é“å¹³é¢ä¸å½¢çŠ¶çš„è€¦åˆ
        # å€¾è§’å’Œåå¿ƒç‡çš„äº¤äº’å¯èƒ½æŒ‡ç¤ºå¹³é¢å˜æ›´å’Œè½¨é“å½¢çŠ¶è°ƒæ•´çš„åŒæ­¥æ€§
        if 'inclination_diff_1' in df.columns and 'eccentricity_diff_1' in df.columns:
            df['inc_ecc_change_sync'] = df['inclination_diff_1'] * df['eccentricity_diff_1']

        # 3. ç»¼åˆå˜åŒ–ç‡
        # å°†ä¸»è¦å‚æ•°çš„å˜åŒ–ç‡ç›¸åŠ ï¼Œæ”¾å¤§æ€»ä½“å˜åŒ–ä¿¡å·
        change_cols = [f'{col}_diff_1' for col in self.all_process_cols if f'{col}_diff_1' in df.columns]
        if len(change_cols) > 1:
            df['composite_change_rate'] = df[change_cols].abs().sum(axis=1)
            # 7æ—¥æ»šåŠ¨å˜åŒ–ç‡ï¼Œè§‚å¯Ÿè¿‘æœŸå˜åŒ–çš„å‰§çƒˆç¨‹åº¦
            df['composite_change_rolling_7d'] = df['composite_change_rate'].rolling(7).mean()

        return df

    def _add_geo_specific_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ã€å¼ºåŒ–ç‰ˆã€‘ä¸ºGEOå«æ˜Ÿæ·»åŠ åŸºäºç‰©ç†çš„æ¼‚ç§»å’Œå‹åŠ›ç‰¹å¾"""
        print("   -> Adding ENHANCED GEO-specific features...")
        
        # æˆ‘ä»¬å°†å¤„ç†æ‰€æœ‰æ ¸å¿ƒè½¨é“æ ¹æ•°
        cols_for_drift_analysis = [self.target_column] + self.additional_columns
        
        for col in cols_for_drift_analysis:
            if col not in df.columns: continue

            # å®šä¹‰é•¿çŸ­æœŸçª—å£
            long_window = 60
            short_window = 14
            
            # --- ç‰¹å¾1: ç¬æ—¶æ¼‚ç§» (Deviation from long-term mean) ---
            # è®¡ç®—ä¸€ä¸ªé•¿æœŸçš„ã€ç¨³å®šçš„ç§»åŠ¨å¹³å‡çº¿ä½œä¸ºâ€œæ­£å¸¸â€è½¨é“ä¸­å¿ƒ
            long_term_mean = df[col].rolling(window=long_window, min_periods=long_window//2).mean()
            df[f'{col}_drift_from_long_mean'] = df[col] - long_term_mean

            # --- ç‰¹å¾2: ç´¯ç§¯æ¼‚ç§»å‹åŠ› (Accumulated Drift Pressure) ---
            # è®¡ç®—çŸ­æœŸæ¼‚ç§»çš„ç´¯ç§¯å’Œï¼Œé‡åŒ–â€œä¿®æ­£å‹åŠ›â€
            # å½“è¿™ä¸ªå€¼æŒç»­å¢å¤§æˆ–å‡å°ï¼Œè¯´æ˜æœºåŠ¨å³å°†å‘ç”Ÿ
            if f'{col}_drift_from_long_mean' in df.columns:
                df[f'{col}_cumulative_drift_{short_window}d'] = df[f'{col}_drift_from_long_mean'].rolling(window=short_window).sum()
                
            # --- ç‰¹å¾3: æ¼‚ç§»é€Ÿåº¦ (Rate of Drift) ---
            # æˆ‘ä»¬å·²æœ‰çš„ trend_slope ç‰¹å¾åœ¨è¿™é‡Œæ‰®æ¼”äº†å…³é”®è§’è‰²ï¼Œæ— éœ€é‡å¤æ·»åŠ ã€‚
            # df[f'{col}_trend_slope_14'] å’Œ df[f'{col}_trend_slope_30'] å°†æ˜¯æ ¸å¿ƒé¢„æµ‹å› å­ã€‚

            # --- ç‰¹å¾4: æ¼‚ç§»åŠ é€Ÿåº¦ (Acceleration of Drift) ---
            # æ¼‚ç§»é€Ÿåº¦æœ¬èº«çš„å˜åŒ–ç‡ï¼Œå¯ä»¥ä½œä¸ºæœºåŠ¨ä¸´è¿‘çš„æ›´å¼ºä¿¡å·
            if f'{col}_trend_slope_7' in df.columns:
                 df[f'{col}_drift_acceleration_7d'] = df[f'{col}_trend_slope_7'].diff()

        return df

    def _add_leo_specific_features(self, df: pd.DataFrame) -> pd.DataFrame:
        print("   -> Adding LEO-specific features...")
        
        for col in self.all_process_cols:
            if col not in df.columns:
                continue
            
            if f'{col}_diff_1' in df.columns and f'{col}_rolling_std_7' in df.columns:
                df[f'{col}_sharp_change'] = (
                    abs(df[f'{col}_diff_1']) > df[f'{col}_rolling_std_7'] * 2
                ).astype(int)
                
                df[f'{col}_consecutive_change'] = (
                    df[f'{col}_sharp_change'].rolling(3).sum()
                )
        
        return df

    def prepare_target_features(self, df: pd.DataFrame, forecast_horizon: int = 1) -> pd.DataFrame:
        result_df = df.copy()
        result_df['target'] = result_df[self.target_column].shift(-forecast_horizon)
        return result_df
    


def create_drift_enhanced_features(tle_data, scaling_factor, target_col='mean_motion'):
    """
    ä¸€ä¸ªç‹¬ç«‹çš„ã€å¯é‡ç”¨çš„ç‰¹å¾å·¥ç¨‹å‡½æ•°
    """
    print("\nğŸ› ï¸ åˆ›å»ºæ¼‚ç§»å¢å¼ºç‰¹å¾")
    print("-" * 20)
    
    data = tle_data.set_index('epoch').copy()
    base_cols = ['mean_motion', 'eccentricity', 'inclination']
    available_cols = [col for col in base_cols if col in data.columns]
    
    if not available_cols:
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ°åŸºç¡€ç‰¹å¾åˆ—: {base_cols}")
        return None
    
    print(f"   åŸºç¡€å‚æ•°: {available_cols}")
    enhanced_data = data[available_cols].copy()
    
    lags = [1, 2, 3, 7]
    windows = [3, 7, 14]
    for col in available_cols:
        for lag in lags:
            enhanced_data[f'{col}_lag_{lag}'] = data[col].shift(lag)
        for window in windows:
            enhanced_data[f'{col}_rolling_mean_{window}'] = data[col].rolling(window, min_periods=window//2).mean()
            enhanced_data[f'{col}_rolling_std_{window}'] = data[col].rolling(window, min_periods=window//2).std()
        enhanced_data[f'{col}_diff_1'] = data[col].diff(1)
        enhanced_data[f'{col}_diff_7'] = data[col].diff(7)

    long_windows = [30, 60]
    for col in available_cols:
        for window in long_windows:
            long_mean = data[col].rolling(window, min_periods=window//3).mean()
            long_std = data[col].rolling(window, min_periods=window//3).std()
            enhanced_data[f'{col}_drift_from_{window}d'] = data[col] - long_mean
            enhanced_data[f'{col}_drift_zscore_{window}d'] = (data[col] - long_mean) / (long_std + 1e-8)

    trend_windows = [7, 14]
    for col in available_cols:
        for window in trend_windows:
            enhanced_data[f'{col}_trend_{window}d'] = data[col].rolling(window).apply(
                lambda x: (x[-1] - x[0]) / len(x) if len(x) > 1 else 0, raw=True)

    for col in available_cols:
        short_mean = data[col].rolling(7, min_periods=3).mean()
        short_drift = (data[col] - short_mean).abs()
        enhanced_data[f'{col}_cumulative_drift_7d'] = short_drift.rolling(7, min_periods=3).sum()
        enhanced_data[f'{col}_cumulative_drift_14d'] = short_drift.rolling(14, min_periods=7).sum()

    if len(available_cols) > 1:
        for window in [7, 14]:
            drift_cols = [f'{col}_drift_from_30d' for col in available_cols if f'{col}_drift_from_30d' in enhanced_data.columns]
            if drift_cols:
                enhanced_data[f'combined_drift_l2_{window}d'] = np.sqrt(enhanced_data[drift_cols].pow(2).sum(axis=1))

    # åˆ›å»ºç›®æ ‡å˜é‡ï¼ˆå·®åˆ†ï¼‰
    mean_motion_diff = data[target_col].diff()
    enhanced_data['target'] = mean_motion_diff.shift(-1).abs()

    # âœ… æ— éœ€ç­›é€‰å°å€¼ï¼šä¿ç•™æ‰€æœ‰éNaNï¼Œç›´æ¥åšæ”¾å¤§å¤„ç†ï¼ˆé‡ç‚¹ï¼ï¼ï¼‰
    enhanced_data = enhanced_data.dropna(subset=['target'])

    # âœ… æ•°å€¼æ”¾å¤§ + log1pï¼Œæå‡æ•°å€¼å¯å­¦ä¹ æ€§
    enhanced_data['target'] = enhanced_data['target'] * 1e8

    # æ‰“å°ç¡®è®¤
    print("âœ… åº”ç”¨äº† log1p(target * 1e8) å˜æ¢")
    print(enhanced_data['target'].describe())
    


    # å¡«å……å…¶ä»–ç‰¹å¾
    # [MODIFIED] Use .ffill() and .bfill() which are the modern replacements for method='...'
    enhanced_data = enhanced_data.ffill(limit=3)
    enhanced_data = enhanced_data.bfill(limit=3)
    
    # [MODIFIED] Loop through columns and fill remaining NaNs using direct assignment
    # to avoid SettingWithCopyWarning.
    for col in enhanced_data.columns:
        if enhanced_data[col].isna().any():
            median_val = enhanced_data[col].median()
            # Use assignment `=` instead of `inplace=True` on a chained call
            enhanced_data[col] = enhanced_data[col].fillna(median_val if not pd.isna(median_val) else 0)

    print(f"âœ… ç‰¹å¾åˆ›å»ºå®Œæˆ")
    print(f"   ç‰¹å¾æ•°é‡: {len(enhanced_data.columns)}")
    print(f"   æœ‰æ•ˆè®°å½•: {len(enhanced_data)}")
    print(f"   ç›®æ ‡å˜é‡ç»Ÿè®¡: mean={enhanced_data['target'].mean():.6f}, std={enhanced_data['target'].std():.6f}")
    return enhanced_data

def create_drift_features(tle_data, target_col='mean_motion'):
    """
    åˆ›å»ºæ¼‚ç§»ç›¸å…³çš„ç‰¹å¾
    
    ç‰¹å¾1ï¼šé‡åŒ–"æŒç»­æ¼‚ç§»" - æè¿°å‚æ•°åç¦»å…¶æ­£å¸¸ä¸­å¿ƒçš„ç¨‹åº¦
    ç‰¹å¾2ï¼šå¼•å…¥"ç´¯ç§¯æ¼‚ç§»å‹åŠ›" - æ¼‚ç§»æ˜¯æŒç»­ç´¯ç§¯çš„
    """
    print("\nğŸ› ï¸ åˆ›å»ºæ¼‚ç§»ç‰¹å¾")
    print("-" * 20)
    
    data = tle_data.set_index('epoch').copy()
    
    # åŸºç¡€è½¨é“å‚æ•°
    orbit_params = ['mean_motion', 'eccentricity', 'inclination']
    available_params = [col for col in orbit_params if col in data.columns]
    
    if not available_params:
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ°è½¨é“å‚æ•°åˆ—: {orbit_params}")
        return None
    
    print(f"   åŸºç¡€è½¨é“å‚æ•°: {available_params}")
    
    enhanced_data = data[available_params].copy()
    
    # ==== ç‰¹å¾1ï¼šé‡åŒ–æŒç»­æ¼‚ç§» ====
    long_windows = [15, 30, 45]  
    
    for col in available_params:
        for window in long_windows:
            col_mean = data[col].rolling(window, min_periods=window//2).mean()
            enhanced_data[f'{col}_drift_from_{window}d_mean'] = data[col] - col_mean
            col_std = data[col].rolling(window, min_periods=window//2).std()
            enhanced_data[f'{col}_drift_zscore_{window}d'] = (data[col] - col_mean) / (col_std + 1e-8)
    
    trend_windows = [7, 14, 21]
    for col in available_params:
        for window in trend_windows:
            enhanced_data[f'{col}_trend_slope_{window}d'] = data[col].rolling(window).apply(
                lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) > 1 else 0
            )
    
    # ==== ç‰¹å¾2ï¼šç´¯ç§¯æ¼‚ç§»å‹åŠ› ====
    short_windows = [3, 7, 14]
    
    for col in available_params:
        short_mean = data[col].rolling(7).mean()
        short_drift = (data[col] - short_mean).abs()
        
        for window in short_windows:
            enhanced_data[f'{col}_cumulative_drift_{window}d'] = short_drift.rolling(window).sum()
            weights = np.exp(np.linspace(-1, 0, window))
            enhanced_data[f'{col}_weighted_cumulative_drift_{window}d'] = short_drift.rolling(window).apply(
                lambda x: np.sum(x * weights[-len(x):]) / np.sum(weights[-len(x):])
            )
    
    # ==== ç‰¹å¾3ï¼šå‚æ•°é—´çš„ååŒæ¼‚ç§» ====
    if len(available_params) > 1:
        for window in [7, 14]:
            drift_cols = [f'{col}_drift_from_{window}d_mean' for col in available_params 
                          if f'{col}_drift_from_{window}d_mean' in enhanced_data.columns]
            if drift_cols:
                enhanced_data[f'combined_drift_l2_{window}d'] = np.sqrt(
                    enhanced_data[drift_cols].pow(2).sum(axis=1)
                )
                enhanced_data[f'drift_correlation_{window}d'] = enhanced_data[drift_cols].apply(
                    lambda x: 1 if (x > 0).all() or (x < 0).all() else 0, axis=1
                )
    
    # ==== ç‰¹å¾4ï¼šå†å²æœºåŠ¨æ¨¡å¼ç‰¹å¾ ====
    for col in available_params:
        col_diff = data[col].diff().abs()
        threshold = col_diff.quantile(0.95)
        events = (col_diff > threshold).astype(int)
        last_event_idx = pd.Series(range(len(events)), index=events.index)
        last_event_idx[events == 0] = np.nan
        last_event_idx = last_event_idx.ffill()
        enhanced_data[f'{col}_days_since_last_jump'] = (
            pd.Series(range(len(events)), index=events.index) - last_event_idx
        )
    
    # ==== ç‰¹å¾5ï¼šç»Ÿè®¡ç‰¹å¾ ====
    stat_windows = [3, 7, 14, 30]
    for col in available_params:
        for window in stat_windows:
            enhanced_data[f'{col}_rolling_mean_{window}d'] = data[col].rolling(window).mean()
            enhanced_data[f'{col}_rolling_std_{window}d'] = data[col].rolling(window).std()
            enhanced_data[f'{col}_rolling_skew_{window}d'] = data[col].rolling(window).skew()
            enhanced_data[f'{col}_rolling_kurt_{window}d'] = data[col].rolling(window).kurt()
    
    # ==== å­¦ä¹ ç›®æ ‡ï¼šé¢„æµ‹æœºåŠ¨å¼•èµ·çš„è·³å˜ ====
    enhanced_data['target'] = data[target_col].diff().shift(-1)
    enhanced_data['target_abs'] = enhanced_data['target'].abs()
    
    # --- ä½¿ç”¨æ›´å¥å£®çš„NaNå¤„ç†æ–¹å¼ ---
    enhanced_data = enhanced_data.dropna(subset=['target', 'target_abs'])
    print(f"   è®°å½•æ•° (åœ¨ä¸¢å¼ƒæ— æ•ˆç›®æ ‡å): {len(enhanced_data)}")

    feature_cols = [col for col in enhanced_data.columns if col not in ['target', 'target_abs']]
    enhanced_data[feature_cols] = enhanced_data[feature_cols].ffill().bfill()

    for col in feature_cols:
        if enhanced_data[col].isnull().any():
            median_val = enhanced_data[col].median()
            if not pd.isna(median_val):
                enhanced_data[col] = enhanced_data[col].fillna(median_val)
            else:
                enhanced_data[col] = enhanced_data[col].fillna(0)
    
    print(f"âœ… ç‰¹å¾å’ŒNaNå€¼å¤„ç†å®Œæˆ")
    print(f"   ç‰¹å¾æ•°é‡: {len(enhanced_data.columns)}")
    print(f"   æœ‰æ•ˆè®°å½•: {len(enhanced_data)}")
    
    print("\nğŸ“Š å…³é”®ç‰¹å¾ç»Ÿè®¡:")
    key_features = [col for col in enhanced_data.columns if 'drift' in col or 'cumulative' in col][:5]
    for feat in key_features:
        if feat in enhanced_data.columns:
            print(f"   {feat}: mean={enhanced_data[feat].mean():.6f}, std={enhanced_data[feat].std():.6f}")
    
    return enhanced_data