#!/usr/bin/env python
"""
Enhanced ARIMA-based Satellite Maneuver Detector
Based on technical documentation and improved implementation
"""

import os
import sys
from pathlib import Path
from datetime import datetime, timedelta
import argparse
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.stattools import adfuller
import warnings
warnings.filterwarnings('ignore')

# Add project path
ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

# è¿™äº›ä¾èµ–åªåœ¨ main ä¸­ä½¿ç”¨ï¼›å¦‚æœä½ çš„å·¥ç¨‹æ²¡æœ‰å®ƒä»¬ï¼Œä¹Ÿä¸å½±å“æœ¬ detector çš„ç‹¬ç«‹ä½¿ç”¨
try:
    from src.data.loader import SatelliteDataLoader
    from src.utils.metrics import evaluate_detection
except Exception:
    SatelliteDataLoader = None
    evaluate_detection = None


class EnhancedARIMADetector:
    """
    å¢å¼ºç‰ˆ ARIMA æœºåŠ¨æ£€æµ‹å™¨ï¼š
    - æ‹Ÿåˆå¤±è´¥è‡ªåŠ¨å›é€€ï¼ˆcss-mle â†’ cssï¼‰
    - åŠ¨æ€æ›´æ–°ï¼šæŒ‰é—´éš”å¯¹æœ€è¿‘çŸ­çª—é‡æ‹Ÿåˆï¼ˆå¤±è´¥å¿½ç•¥ï¼‰
    - è‡ªé€‚åº”é˜ˆå€¼ï¼šå…¨å±€/æœ¬åœ°æ³¢åŠ¨èåˆ + æœ«æ®µè½»å¾®é™é˜ˆå€¼ + ä¸‹ç•Œä¿æŠ¤
    - ç›¸é‚»å¼‚å¸¸èšç±»å»é‡ï¼šç›¸é‚»â‰¤Nå¤©ä»…ä¿ç•™åˆ†æ•°æœ€é«˜çš„ä¸€ç‚¹
    """

    def __init__(
        self,
        p: int = 5,
        d: int = 1,
        q: int = 1,
        rolling_window: int = 30,
        adaptive_threshold: bool = True,
        threshold_factor: float = 2.5,
        min_threshold_factor: float = 1.5,
        max_threshold_factor: float = 4.0,
        min_gap_days: int = 3,
    ):
        self.p = int(p)
        self.d = int(d)
        self.q = int(q)
        self.rolling_window = int(rolling_window)
        self.adaptive_threshold = bool(adaptive_threshold)
        self.threshold_factor = float(threshold_factor)
        self.min_threshold_factor = float(min_threshold_factor)
        self.max_threshold_factor = float(max_threshold_factor)
        self.min_gap_days = int(min_gap_days)

        self.model_fit = None
        self.global_std: float = 0.0
        self.baseline_residuals: pd.Series | None = None

    # ------------------ æ‹Ÿåˆ ------------------
    def fit(self, train_data: pd.Series):
        """åœ¨è®­ç»ƒé›†ä¸Šæ‹Ÿåˆ ARIMAï¼Œå¹¶è®°å½•åŸºçº¿æ®‹å·®ä¸å…¨å±€æ³¢åŠ¨ã€‚"""
        y = self._ensure_series(train_data).dropna()
        print(f"Fitting ARIMA({self.p},{self.d},{self.q}) on {len(y)} training points...")

        # å¹³ç¨³æ€§æŠ¥å‘Šï¼ˆä¸å¼ºåˆ¶ï¼‰
        try:
            adf_stat, adf_p, *_ = adfuller(y)
            print(f"  ADF Statistic: {adf_stat:.4f}, p-value: {adf_p:.4f}")
        except Exception as e:
            print(f"  ADF check skipped: {e}")

        # ä¸»æ‹Ÿåˆï¼šcss-mleï¼Œå¤±è´¥å›é€€ css
        self.model_fit = self._fit_with_fallback(y)

        # åŸºçº¿ç»å¯¹æ®‹å·®ä¸å…¨å±€ std
        resid = np.abs(pd.Series(self.model_fit.resid, index=y.index[-len(self.model_fit.resid):]))
        self.baseline_residuals = resid.dropna()
        self.global_std = float(np.nanstd(self.baseline_residuals)) if len(self.baseline_residuals) else 0.0

        print(f"  Model AIC: {self.model_fit.aic:.2f}")
        print(f"  Baseline residual std: {self.global_std:.6f}")
        return self

    def _fit_with_fallback(self, series: pd.Series):
        """ä¼˜å…ˆ css-mleï¼Œå¤±è´¥å›é€€ cssã€‚"""
        for method, maxiter in (("css-mle", 200), ("css", 100)):
            try:
                model = ARIMA(series, order=(self.p, self.d, self.q))
                fit = model.fit(method=method, maxiter=maxiter)
                return fit
            except Exception:
                continue
        raise RuntimeError("ARIMA fit failed with both 'css-mle' and 'css'.")

    # ------------------ æ£€æµ‹ ------------------
    def detect(self, test_data: pd.Series, dynamic_update: bool = True) -> pd.DataFrame:
        """
        å¯¹æµ‹è¯•é›†é€ç‚¹æ£€æµ‹ã€‚è¿”å› DataFrameï¼ˆç´¢å¼•ä¸ºæ—¶é—´ï¼‰ï¼ŒåŒ…å«åˆ—ï¼š
        ['actual','forecast','residual','threshold','score','is_anomaly']
        """
        if self.model_fit is None:
            raise RuntimeError("Model not fitted. Call fit() first.")

        y = self._ensure_series(test_data)
        print(f"\nDetecting anomalies on {len(y)} test points...")

        rw = self.rolling_window
        update_interval = max(10, rw // 3)
        last_update_i = 0

        results = {
            "actual": [],
            "forecast": [],
            "residual": [],
            "threshold": [],
            "score": [],
            "is_anomaly": [],
        }

        # é€ç‚¹å¤„ç†
        for i, (t, val) in enumerate(y.items()):
            try:
                # åŠ¨æ€æ›´æ–°ï¼šæ¯éš” update_intervalï¼Œç”¨æœ€è¿‘ 2*rw çª—å£é‡æ‹Ÿåˆ
                if dynamic_update and i > 0 and (i - last_update_i) >= update_interval:
                    win_start = max(0, i - 2 * rw)
                    recent = y.iloc[win_start:i].dropna()
                    if len(recent) > (self.p + self.d + self.q + 2):
                        try:
                            self.model_fit = self._fit_with_fallback(recent)
                            last_update_i = i
                        except Exception:
                            pass  # å¿½ç•¥ï¼Œç»§ç»­ç”¨æ—§æ¨¡å‹

                # ä¸€æ­¥é¢„æµ‹
                try:
                    yhat = float(self.model_fit.forecast(steps=1)[0])
                except Exception:
                    # æç«¯æƒ…å†µä¸‹ï¼Œç”¨ä¸Šä¸€å®å€¼å›é€€
                    yhat = float(results["actual"][-1]) if results["actual"] else float(val)

                resid = abs(float(val) - yhat)

                # è‡ªé€‚åº”é˜ˆå€¼ï¼ˆèåˆå…¨å±€/æœ¬åœ°æ³¢åŠ¨ï¼‰
                recent_resid = results["residual"][-rw:] if results["residual"] else [resid]
                th = self._calculate_adaptive_threshold(recent_resid, i, len(y))

                score = resid / max(th, 1e-12)
                is_anom = score > 1.0

                # è®°å½•
                results["actual"].append(float(val))
                results["forecast"].append(yhat)
                results["residual"].append(resid)
                results["threshold"].append(float(th))
                results["score"].append(float(score))
                results["is_anomaly"].append(1 if is_anom else 0)

            except Exception as e:
                # å…œåº•ï¼šä¸ä¸­æ–­æµç¨‹
                prev_fore = results["forecast"][-1] if results["forecast"] else float(val)
                results["actual"].append(float(val))
                results["forecast"].append(float(prev_fore))
                results["residual"].append(0.0)
                results["threshold"].append(float(max(self.global_std, 1e-12) * max(self.threshold_factor, 1.0)))
                results["score"].append(0.0)
                results["is_anomaly"].append(0)
                print(f"  [warn] detect step {i} fallback due to: {e}")

        df = pd.DataFrame(results, index=y.index)

        # ç›¸é‚»å¼‚å¸¸èšç±»å»é‡ï¼ˆâ‰¤min_gap_days, å–åˆ†æ•°æœ€é«˜ï¼‰
        df = self._cluster_anomalies(df, min_gap_days=self.min_gap_days)

        print(f"Detection complete. Found {int(df['is_anomaly'].sum())} anomalies.")
        return df

    # ------------------ é˜ˆå€¼ä¸èšç±» ------------------
    def _calculate_adaptive_threshold(self, recent_residuals: list[float], position: int, total_len: int) -> float:
        """èåˆå…¨å±€/æœ¬åœ°æ³¢åŠ¨å¹¶åŠ ä¸‹ç•Œä¿æŠ¤ã€‚"""
        # åŸºçº¿ï¼šå…¨å±€ std Ã— å› å­
        factor = float(np.clip(self.threshold_factor, self.min_threshold_factor, self.max_threshold_factor))
        base = max(self.global_std, 1e-12) * factor

        if not self.adaptive_threshold or len(recent_residuals) < 5:
            th = base
        else:
            local_std = float(np.nanstd(recent_residuals))
            local_mean = float(np.nanmean(recent_residuals))
            vol_ratio = local_std / max(self.global_std, 1e-12)

            # æ ¹æ®æ³¢åŠ¨æ¯”å¾®è°ƒå› å­ï¼ˆæŠ‘åˆ¶è¿‡ä½é˜ˆå€¼ / é™ä½è¯¯æŠ¥ï¼‰
            if vol_ratio > 1.5:
                adj = min(self.max_threshold_factor, factor * (1 + 0.3 * (vol_ratio - 1)))
            elif vol_ratio < 0.5:
                adj = max(self.min_threshold_factor, factor * (0.7 + 0.6 * vol_ratio))
            else:
                adj = factor

            # èåˆï¼ˆåå‘å…¨å±€ï¼Œå…¼é¡¾æœ¬åœ°ï¼‰
            th = 0.7 * base + 0.3 * (local_mean + adj * local_std)

        # æœ«æ®µæ›´æ•æ„Ÿä¸€ç‚¹
        if position >= int(0.8 * total_len):
            th *= 0.95

        # é˜ˆå€¼ä¸‹ç•Œä¿æŠ¤ï¼šè‡³å°‘ä¸ºå…¨å±€ std çš„ä¸€åŠï¼ˆåŒé‡çº²ï¼‰
        return float(max(th, 0.5 * max(self.global_std, 1e-12)))

    def _cluster_anomalies(self, df: pd.DataFrame, min_gap_days: int = 3) -> pd.DataFrame:
        """å°†ç›¸é‚»â‰¤min_gap_daysçš„å¼‚å¸¸åˆå¹¶ä¸º1ä¸ªï¼šåªä¿ç•™ç°‡å†…åˆ†æ•°æœ€é«˜ç‚¹ã€‚"""
        anom = df.index[df["is_anomaly"] == 1]
        if len(anom) == 0:
            return df.copy()

        keep_mask = pd.Series(0, index=df.index, dtype=int)

        # é€ç°‡æ‰«æ
        cluster = [anom[0]]
        for i in range(1, len(anom)):
            if (anom[i] - anom[i - 1]) <= timedelta(days=min_gap_days):
                cluster.append(anom[i])
            else:
                # ç»“æŸä¸Šä¸€ç°‡
                best_idx = df.loc[cluster, "score"].idxmax()
                keep_mask.loc[best_idx] = 1
                cluster = [anom[i]]

        # æœ€åä¸€ç°‡
        if cluster:
            best_idx = df.loc[cluster, "score"].idxmax()
            keep_mask.loc[best_idx] = 1

        out = df.copy()
        out["is_anomaly"] = keep_mask
        return out

    # ------------------ å°å·¥å…· ------------------
    @staticmethod
    def _ensure_series(series: pd.Series) -> pd.Series:
        if not isinstance(series, pd.Series):
            raise TypeError("Input must be a pandas Series.")
        if not isinstance(series.index, (pd.DatetimeIndex, pd.PeriodIndex)):
            try:
                series.index = pd.to_datetime(series.index)
            except Exception:
                raise ValueError("Series index must be datetime-like.")
        return series.sort_index().astype(float)

    # ä¾¿æ·æ–¹æ³•
    def set_threshold_factor(self, factor: float):
        self.threshold_factor = float(factor)


# ------------------ é˜ˆå€¼å¯»ä¼˜ï¼ˆçª—å£ç»Ÿä¸€ Â±2 å¤©ï¼‰ ------------------
def auto_tune_arima_order(train_data, max_p=7, max_d=2, max_q=3):
    """ç®€æ˜“ AIC ç½‘æ ¼æœç´¢ã€‚"""
    print("\nğŸ”§ Auto-tuning ARIMA parameters...")
    best_aic = np.inf
    best_order = (1, 1, 1)
    tested = 0
    for p in range(1, max_p + 1):
        for d in range(0, max_d + 1):
            for q in range(0, max_q + 1):
                if p + d + q > 10:
                    continue
                try:
                    fit = ARIMA(train_data, order=(p, d, q)).fit(method="css", maxiter=50)
                    if fit.aic < best_aic:
                        best_aic, best_order = fit.aic, (p, d, q)
                    tested += 1
                    if tested % 10 == 0:
                        print(f"  Tested {tested} models... Current best: {best_order} (AIC: {best_aic:.2f})")
                except Exception:
                    continue
    print(f"âœ… Best ARIMA order: {best_order} (AIC: {best_aic:.2f})")
    return best_order


def find_optimal_threshold_factor(detector, val_data, val_labels, factor_range=(1.5, 4.0), n_trials=20):
    """
    åœ¨éªŒè¯é›†ä¸Šå¯»ä¼˜é˜ˆå€¼å› å­ã€‚çª—å£ç»Ÿä¸€ä¸º Â±2 å¤©ã€‚
    """
    print("\nğŸ¯ Optimizing threshold factor on validation set (Â±2 days)...")
    factors = np.linspace(factor_range[0], factor_range[1], n_trials)
    best_f1, best_factor = 0.0, float(detector.threshold_factor)

    for f in factors:
        detector.set_threshold_factor(f)
        df = detector.detect(val_data, dynamic_update=False)
        pred_times = df.index[df["is_anomaly"] == 1].tolist()
        true_times = val_labels[val_labels == 1].index.tolist()

        if len(pred_times) == 0 and len(true_times) == 0:
            f1 = 1.0
        else:
            # è®¡æ•°ï¼šÂ±2 å¤©åŒ¹é…
            tp = 0
            used = set()
            for t in pred_times:
                for j, gt in enumerate(true_times):
                    if j in used:
                        continue
                    if abs((t - gt).days) <= 2:
                        tp += 1
                        used.add(j)
                        break
            fp = max(len(pred_times) - tp, 0)
            fn = max(len(true_times) - tp, 0)
            prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0
            rec = tp / (tp + fn) if (tp + fn) > 0 else 0.0
            f1 = (2 * prec * rec / (prec + rec)) if (prec + rec) > 0 else 0.0

        if f1 > best_f1:
            best_f1, best_factor = f1, float(f)

    print(f"âœ… Best threshold factor: {best_factor:.2f} (F1: {best_f1:.3f})")
    detector.set_threshold_factor(best_factor)
    return best_factor, best_f1


# ------------------ å¯è§†åŒ– ------------------
def visualize_results(results_df, maneuver_times, satellite_name, element, output_dir):
    """
    Create comprehensive visualization of detection results
    """
    print("\nğŸ“Š Creating visualizations...")

    fig = plt.figure(figsize=(18, 12))

    # 1. æ—¶åºä¸æ£€æµ‹
    ax1 = plt.subplot(3, 1, 1)
    ax1.plot(results_df.index, results_df["actual"], '-', label='Actual', linewidth=1.5, alpha=0.85)
    ax1.plot(results_df.index, results_df["forecast"], '--', label='ARIMA Forecast', linewidth=1.0, alpha=0.8)

    anomaly_points = results_df[results_df["is_anomaly"] == 1]
    ax1.scatter(anomaly_points.index, anomaly_points["actual"], s=80, marker='x', label='Detected', zorder=5)

    for m_time in maneuver_times:
        if results_df.index.min() <= m_time <= results_df.index.max():
            ax1.axvline(m_time, linestyle='--', alpha=0.45, linewidth=1.2)

    ax1.set_title(f'{satellite_name} - {element.replace("_", " ").title()} - ARIMA Detection', fontsize=14)
    ax1.set_ylabel('Value')
    ax1.legend(loc='upper left')
    ax1.grid(True, alpha=0.3)

    # 2. æ®‹å·®ä¸é˜ˆå€¼
    ax2 = plt.subplot(3, 1, 2)
    ax2.plot(results_df.index, results_df["residual"], '-', label='Residual', linewidth=1.0, alpha=0.8)
    ax2.plot(results_df.index, results_df["threshold"], '--', label='Adaptive Threshold', linewidth=1.2)
    ax2.fill_between(results_df.index, 0, results_df["threshold"], alpha=0.18)
    ax2.set_ylabel('Residual / Threshold')
    ax2.legend(loc='upper left')
    ax2.grid(True, alpha=0.3)

    # 3. åˆ†æ•°
    ax3 = plt.subplot(3, 1, 3)
    ax3.plot(results_df.index, results_df["score"], label='Score', linewidth=1.0)
    ax3.axhline(y=1.0, linestyle='--', label='Decision', linewidth=1.2)
    for idx in anomaly_points.index:
        ax3.axvline(idx, alpha=0.25, linewidth=1.2)
    ax3.set_xlabel('Date')
    ax3.set_ylabel('Score')
    ax3.legend(loc='upper left')
    ax3.grid(True, alpha=0.3)

    plt.tight_layout()
    output_path = output_dir / f"{satellite_name}_{element}_enhanced_arima.png"
    plt.savefig(output_path, dpi=200, bbox_inches='tight')
    plt.close()
    print(f"âœ… Visualization saved to {output_path}")


# ------------------ å¯æ‰§è¡Œå…¥å£ï¼ˆå¯é€‰ä½¿ç”¨ï¼›ä½ çš„å·¥ç¨‹è‹¥ä¸ç”¨å¯å¿½ç•¥ï¼‰ ------------------
def main():
    parser = argparse.ArgumentParser(description="Enhanced ARIMA Maneuver Detection")
    parser.add_argument("satellite", help="Satellite name (e.g., Fengyun-4A)")
    parser.add_argument("--element", default="mean_motion", help="Orbital element to analyze (default: mean_motion)")
    parser.add_argument("--auto-tune", action="store_true", help="Auto-tune ARIMA parameters")
    parser.add_argument("--optimize-threshold", action="store_true", help="Optimize threshold factor")
    parser.add_argument("--min-gap-days", type=int, default=3, help="Cluster nearby anomalies within N days")
    args = parser.parse_args()

    # å¦‚æœä½ çš„å·¥ç¨‹æ²¡æœ‰è¿™äº›æ¨¡å—ï¼Œmain å¯ä»¥ä¸èµ°ï¼›detector ä¸å—å½±å“
    if SatelliteDataLoader is None or evaluate_detection is None:
        print("This executable entry requires project modules (SatelliteDataLoader, evaluate_detection).")
        print("Detector class is ready for import/use.")
        return

    ELEMENT_TO_ANALYZE = args.element
    output_dir = Path("outputs") / f"{args.satellite.replace(' ', '_')}_Enhanced_ARIMA_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    output_dir.mkdir(parents=True, exist_ok=True)

    print(f"\n{'='*60}")
    print(f"ğŸ›°ï¸ Enhanced ARIMA Detection for {args.satellite}")
    print(f"{'='*60}")

    loader = SatelliteDataLoader(data_dir="data")
    tle_data, maneuver_times = loader.load_satellite_data(args.satellite)

    if tle_data is None:
        print("âŒ Failed to load data")
        return

    print(f"âœ… Loaded {len(tle_data)} TLE records and {len(maneuver_times)} maneuvers")

    # æ„é€ æ—¥å°ºåº¦æ—¶åº
    ts_data = tle_data[["epoch", ELEMENT_TO_ANALYZE]].set_index("epoch")
    ts_data = ts_data.resample("D").median().interpolate(method="time").dropna()
    ts_data = ts_data[ELEMENT_TO_ANALYZE]
    print(f"âœ… Prepared time series with {len(ts_data)} daily points")

    # æ ‡ç­¾ï¼ˆÂ±2å¤©çª—å£ï¼‰
    labels = pd.Series(0, index=ts_data.index, dtype=int)
    for m_time in maneuver_times:
        mask = (ts_data.index >= m_time - timedelta(days=2)) & (ts_data.index <= m_time + timedelta(days=2))
        labels.loc[mask] = 1

    # åˆ‡åˆ† 6/2/2
    n = len(ts_data)
    train_end = int(n * 0.6)
    val_end = int(n * 0.8)
    train_data = ts_data.iloc[:train_end]
    val_data = ts_data.iloc[train_end:val_end]
    test_data = ts_data.iloc[val_end:]
    val_labels = labels.iloc[train_end:val_end]
    test_labels = labels.iloc[val_end:]

    # è‡ªåŠ¨å¯»ä¼˜ï¼ˆå¯é€‰ï¼‰
    if args.auto_tune:
        p, d, q = auto_tune_arima_order(train_data)
    else:
        p, d, q = (5, 1, 1)
        print(f"\nUsing default ARIMA({p},{d},{q})")

    # è®­ç»ƒä¸é˜ˆå€¼å¯»ä¼˜
    detector = EnhancedARIMADetector(p=p, d=d, q=q, rolling_window=30, min_gap_days=args.min_gap_days)
    detector.fit(train_data)

    if args.optimize_threshold and len(val_data) > 0:
        best_factor, _ = find_optimal_threshold_factor(detector, val_data, val_labels)
        detector.set_threshold_factor(best_factor)

    # æµ‹è¯•é›†æ£€æµ‹
    print(f"\n{'='*40}")
    print("ğŸ“ˆ Running detection on test set...")
    print(f"{'='*40}")
    results_df = detector.detect(test_data, dynamic_update=True)

    # è¯„ä¼°ï¼ˆÂ±2 å¤©çª—å£ï¼‰
    test_maneuvers = [m for m in maneuver_times if test_data.index.min() <= m <= test_data.index.max()]
    if evaluate_detection is not None and len(test_maneuvers) > 0:
        eval_metrics, matched_pairs = evaluate_detection(
            results_df.index[results_df["is_anomaly"] == 1].tolist(),
            test_maneuvers,
            matching_window=timedelta(days=2),
        )

        print(f"\n{'='*40}")
        print("ğŸ“Š PERFORMANCE METRICS (Â±2 days)")
        print(f"{'='*40}")
        print(f"Precision:  {eval_metrics['precision']:.2%}")
        print(f"Recall:     {eval_metrics['recall']:.2%}")
        print(f"F1 Score:   {eval_metrics['f1']:.3f}")
        print(f"Detected:   {eval_metrics['tp']}/{len(test_maneuvers)} maneuvers")
        print(f"False Alarms: {eval_metrics['fp']}")

    # å¯è§†åŒ–ä¸ä¿å­˜
    visualize_results(results_df, test_maneuvers, args.satellite, ELEMENT_TO_ANALYZE, output_dir)
    results_df.to_csv(output_dir / "detection_results.csv")

    report = {
        "satellite_name": args.satellite,
        "element": ELEMENT_TO_ANALYZE,
        "arima_order": [p, d, q],
        "threshold_factor": detector.threshold_factor,
        "adaptive_threshold": detector.adaptive_threshold,
        "min_gap_days": detector.min_gap_days,
        "performance_window_days": 2,
        "detected_anomalies": [str(t) for t in results_df.index[results_df["is_anomaly"] == 1]],
        "test_maneuvers": [str(t) for t in test_maneuvers],
    }
    with open(output_dir / "detection_report.json", "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, default=str)

    print(f"\nâœ… Results saved to {output_dir}")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()
